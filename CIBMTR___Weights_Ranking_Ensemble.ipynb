{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 70942,
          "databundleVersionId": 10381525,
          "sourceType": "competition"
        },
        {
          "sourceId": 211322530,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 217304343,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 219607918,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 224040652,
          "sourceType": "kernelVersion"
        }
      ],
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "52f5f55523c344f4a77d55291ec2cdb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0d1e847abfd42bbb6afe0f24ccb9b4e",
              "IPY_MODEL_f07c79a3e2bd49ca979086c813ce4369",
              "IPY_MODEL_8804251eab704eb4986fdda86a224ff3"
            ],
            "layout": "IPY_MODEL_48ae913b06e84dc197131204e63fed01"
          }
        },
        "7f768b04d0d948e7a3d4745c3ce1de3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87b12a75c14242edbad7e0b91f2d7352",
            "placeholder": "​",
            "style": "IPY_MODEL_c26e8fcf0fef4ce983c873de1fc1d23e",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "64baeca62d0d48e690f39c6a474a7a76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_86510aa486f843518f8ed0cedba6574e",
            "placeholder": "​",
            "style": "IPY_MODEL_ed5f56522a51423e8e10cb14abf95531",
            "value": "jialingdeng"
          }
        },
        "ad13f90c892f4ae79c6495179d8f9ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_d060d18b21504c20977ee0c690697aaf",
            "placeholder": "​",
            "style": "IPY_MODEL_de8b1016ba324a4eb019d328d91a186e",
            "value": ""
          }
        },
        "1c17499a49db4968b3cb826502455d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_e37e306b47f2490c98c624f369a3ae4d",
            "style": "IPY_MODEL_fba32c2cf72c4d16bd3a6cc4e664d937",
            "tooltip": ""
          }
        },
        "6fdf50765c094321b630d5eb97b29074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cf0bd961e19483084294d20add634a6",
            "placeholder": "​",
            "style": "IPY_MODEL_e2283afa7211440f819f7805e238fcc0",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "48ae913b06e84dc197131204e63fed01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "87b12a75c14242edbad7e0b91f2d7352": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c26e8fcf0fef4ce983c873de1fc1d23e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86510aa486f843518f8ed0cedba6574e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed5f56522a51423e8e10cb14abf95531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d060d18b21504c20977ee0c690697aaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de8b1016ba324a4eb019d328d91a186e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e37e306b47f2490c98c624f369a3ae4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fba32c2cf72c4d16bd3a6cc4e664d937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "4cf0bd961e19483084294d20add634a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2283afa7211440f819f7805e238fcc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69343502a3a140bb92b6dae66791a454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f30087830c474c25be0167bfa6bceece",
            "placeholder": "​",
            "style": "IPY_MODEL_d1601a2072c440eaa462d172970110a9",
            "value": "Connecting..."
          }
        },
        "f30087830c474c25be0167bfa6bceece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1601a2072c440eaa462d172970110a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0d1e847abfd42bbb6afe0f24ccb9b4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef30c324425c4c11b68d97313948bffe",
            "placeholder": "​",
            "style": "IPY_MODEL_b761b7db6ed041f0b89f67d8e2ef93f9",
            "value": "401 Client Error."
          }
        },
        "f07c79a3e2bd49ca979086c813ce4369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d22f04aa57f404aae7eb525243524b2",
            "placeholder": "​",
            "style": "IPY_MODEL_4ef142b295274e6fb26bd69f71d72bae",
            "value": "You don't have permission to access resource at URL: https://www.kaggle.com/api/v1/hello. The server reported the following issues: Unauthenticated"
          }
        },
        "8804251eab704eb4986fdda86a224ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_032b454bff634b4698c0c63f93b2ec5a",
            "placeholder": "​",
            "style": "IPY_MODEL_5902f0438b6f4588bb5c56bb19a872e2",
            "value": "Please make sure you are authenticated if you are trying to access a private resource or a resource requiring consent."
          }
        },
        "ef30c324425c4c11b68d97313948bffe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b761b7db6ed041f0b89f67d8e2ef93f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d22f04aa57f404aae7eb525243524b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef142b295274e6fb26bd69f71d72bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "032b454bff634b4698c0c63f93b2ec5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5902f0438b6f4588bb5c56bb19a872e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "nzo6tNYp8Wch",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464,
          "referenced_widgets": [
            "52f5f55523c344f4a77d55291ec2cdb5",
            "7f768b04d0d948e7a3d4745c3ce1de3a",
            "64baeca62d0d48e690f39c6a474a7a76",
            "ad13f90c892f4ae79c6495179d8f9ec0",
            "1c17499a49db4968b3cb826502455d33",
            "6fdf50765c094321b630d5eb97b29074",
            "48ae913b06e84dc197131204e63fed01",
            "87b12a75c14242edbad7e0b91f2d7352",
            "c26e8fcf0fef4ce983c873de1fc1d23e",
            "86510aa486f843518f8ed0cedba6574e",
            "ed5f56522a51423e8e10cb14abf95531",
            "d060d18b21504c20977ee0c690697aaf",
            "de8b1016ba324a4eb019d328d91a186e",
            "e37e306b47f2490c98c624f369a3ae4d",
            "fba32c2cf72c4d16bd3a6cc4e664d937",
            "4cf0bd961e19483084294d20add634a6",
            "e2283afa7211440f819f7805e238fcc0",
            "69343502a3a140bb92b6dae66791a454",
            "f30087830c474c25be0167bfa6bceece",
            "d1601a2072c440eaa462d172970110a9",
            "c0d1e847abfd42bbb6afe0f24ccb9b4e",
            "f07c79a3e2bd49ca979086c813ce4369",
            "8804251eab704eb4986fdda86a224ff3",
            "ef30c324425c4c11b68d97313948bffe",
            "b761b7db6ed041f0b89f67d8e2ef93f9",
            "0d22f04aa57f404aae7eb525243524b2",
            "4ef142b295274e6fb26bd69f71d72bae",
            "032b454bff634b4698c0c63f93b2ec5a",
            "5902f0438b6f4588bb5c56bb19a872e2"
          ]
        },
        "outputId": "eb90fcb6-434e-4a47-d3ed-b7e666182918"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52f5f55523c344f4a77d55291ec2cdb5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ad8a8d61-0691-42e9-b64f-87e53e7ff1ea\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ad8a8d61-0691-42e9-b64f-87e53e7ff1ea\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-680103b2babb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle credentials set.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "equity_post_hct_survival_predictions_path = kagglehub.competition_download('equity-post-HCT-survival-predictions')\n",
        "cdeotte_pip_install_lifelines_path = kagglehub.notebook_output_download('cdeotte/pip-install-lifelines')\n",
        "albansteff_metric_path = kagglehub.utility_script_install('albansteff/metric')\n",
        "dreamingtree_download_lightning_and_pytorch_tabular_path = kagglehub.notebook_output_download('dreamingtree/download-lightning-and-pytorch-tabular')\n",
        "yunsuxiaozi_yunbase_path = kagglehub.notebook_output_download('yunsuxiaozi/yunbase')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "lRJdzVxS8Wcj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "60d8e59b-ab6a-431f-f319-be142fb5e4c3"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "error",
          "ename": "KaggleApiHTTPError",
          "evalue": "401 Client Error.\n\nYou don't have permission to access resource at URL: https://www.kaggle.com/competitions/equity-post-HCT-survival-predictions\nPlease make sure you are authenticated and have accepted the competition rules which can be found at this location: https://www.kaggle.com/competitions/equity-post-HCT-survival-predictions/rules",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/exceptions.py\u001b[0m in \u001b[0;36mkaggle_api_raise_for_status\u001b[0;34m(response, resource_handle)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://www.kaggle.com/api/v1/competitions/data/download-all/equity-post-HCT-survival-predictions",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKaggleApiHTTPError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2ec8e5e30360>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# NOTEBOOK.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mequity_post_hct_survival_predictions_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompetition_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'equity-post-HCT-survival-predictions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mcdeotte_pip_install_lifelines_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook_output_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cdeotte/pip-install-lifelines'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0malbansteff_metric_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutility_script_install\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'albansteff/metric'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/competition.py\u001b[0m in \u001b[0;36mcompetition_download\u001b[0;34m(handle, path, force_download)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_competition_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading competition: {h.to_url()} ...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mEXTRA_CONSOLE_BLOCK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompetition_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/registry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/resolver.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, handle, path, force_download)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mSome\u001b[0m \u001b[0mcases\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mmight\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCompetition\u001b[0m \u001b[0mdatasource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAPI\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbased\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \"\"\"\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Note handles are immutable, so _resolve() could not have altered our reference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/http_resolver.py\u001b[0m in \u001b[0;36m_resolve\u001b[0;34m(self, h, path, force_download)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mdownload_needed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/clients.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, path, out_file, resource_handle, cached_path, extract_auto_compressed_file)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEFAULT_CONNECT_TIMEOUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_READ_TIMEOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         ) as response:\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mkaggle_api_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mtotal_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"Content-Length\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/exceptions.py\u001b[0m in \u001b[0;36mkaggle_api_raise_for_status\u001b[0;34m(response, resource_handle)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# Default handling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKaggleApiHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKaggleApiHTTPError\u001b[0m: 401 Client Error.\n\nYou don't have permission to access resource at URL: https://www.kaggle.com/competitions/equity-post-HCT-survival-predictions\nPlease make sure you are authenticated and have accepted the competition rules which can be found at this location: https://www.kaggle.com/competitions/equity-post-HCT-survival-predictions/rules"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Notebook Ensemble**\n",
        "- Event-masked PRL-NN --> LB 0.691\n",
        "- CIBMTR Yunbase --> LB 0.689\n",
        "- CIBMTR | EDA & Ensemble Model --> LB 0.689"
      ],
      "metadata": {
        "id": "EvqqYKGV8Wcj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "b7Y9u4Dv8Wcj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Event-masked PRL-NN**\n",
        "\n",
        "https://www.kaggle.com/code/albansteff/event-masked-prl-nn"
      ],
      "metadata": {
        "id": "8jaZwQUV8Wck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Refactoring Pairwise Ranking Network\n",
        "\n",
        "This notebook focuses on adding an event-predicted mask to shift the risk of these subjects. The original idea comes from [this notebook](https://www.kaggle.com/code/kendontcare11/public-classifier-cat-xgb-lb-0-688)"
      ],
      "metadata": {
        "id": "2iFNk9zN8Wck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\n",
        "!pip install -q /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\n",
        "!pip install -q /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\n",
        "!pip install -q /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\n",
        "!pip install -q /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl\n",
        "!pip install -q /kaggle/input/download-lightning-and-pytorch-tabular/pytorch_lightning-2.4.0-py3-none-any.whl\n",
        "!pip install -q /kaggle/input/download-lightning-and-pytorch-tabular/scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
        "!pip install -q /kaggle/input/download-lightning-and-pytorch-tabular/torchmetrics-1.5.2-py3-none-any.whl\n",
        "!pip install -q /kaggle/input/download-lightning-and-pytorch-tabular/pytorch_tabnet-4.1.0-py3-none-any.whl\n",
        "!pip install -q /kaggle/input/download-lightning-and-pytorch-tabular/einops-0.7.0-py3-none-any.whl\n",
        "!pip install -q /kaggle/input/download-lightning-and-pytorch-tabular/pytorch_tabular-1.1.1-py2.py3-none-any.whl"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T15:53:32.901474Z",
          "iopub.execute_input": "2025-02-18T15:53:32.90177Z",
          "iopub.status.idle": "2025-02-18T15:54:18.080211Z",
          "shell.execute_reply.started": "2025-02-18T15:53:32.901747Z",
          "shell.execute_reply": "2025-02-18T15:54:18.079065Z"
        },
        "id": "u-sJNLI68Wck"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGB Classifier to mask further predictions"
      ],
      "metadata": {
        "id": "lax2_m1l8Wck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from metric import score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "\n",
        "ROOT_DATA_PATH = Path(r\"/kaggle/input/equity-post-HCT-survival-predictions\")\n",
        "\n",
        "pd.set_option('display.max_columns', 100)\n",
        "\n",
        "train = pd.read_csv(ROOT_DATA_PATH.joinpath(\"train.csv\"))\n",
        "test = pd.read_csv(ROOT_DATA_PATH.joinpath(\"test.csv\"))\n",
        "\n",
        "CATEGORICAL_VARIABLES = [\n",
        "    # Graft and HCT reasons\n",
        "    'dri_score', 'graft_type', 'prod_type', 'prim_disease_hct',\n",
        "\n",
        "    # Patient health status (risk factors)\n",
        "    'psych_disturb', 'diabetes', 'arrhythmia', 'vent_hist', 'renal_issue', 'pulm_moderate',\n",
        "    'pulm_severe', 'obesity', 'hepatic_mild', 'hepatic_severe', 'peptic_ulcer', 'rheum_issue',\n",
        "    'cardiac', 'prior_tumor', 'mrd_hct', 'tbi_status', 'cyto_score', 'cyto_score_detail',\n",
        "\n",
        "    # Patient demographics\n",
        "    'ethnicity', 'race_group',\n",
        "\n",
        "    # Biological matching with donor\n",
        "    'sex_match', 'donor_related', 'cmv_status', 'tce_imm_match', 'tce_match', 'tce_div_match',\n",
        "\n",
        "    # Medication/operation related data\n",
        "    'melphalan_dose', 'rituximab', 'gvhd_proph', 'in_vivo_tcd', 'conditioning_intensity'\n",
        "]\n",
        "\n",
        "HLA_COLUMNS = [\n",
        "    'hla_match_a_low', 'hla_match_a_high',\n",
        "    'hla_match_b_low', 'hla_match_b_high',\n",
        "    'hla_match_c_low', 'hla_match_c_high',\n",
        "    'hla_match_dqb1_low', 'hla_match_dqb1_high',\n",
        "    'hla_match_drb1_low', 'hla_match_drb1_high',\n",
        "\n",
        "    # Matching at HLA-A(low), -B(low), -DRB1(high)\n",
        "    'hla_nmdp_6',\n",
        "    # Matching at HLA-A,-B,-DRB1 (low or high)\n",
        "    'hla_low_res_6', 'hla_high_res_6',\n",
        "    # Matching at HLA-A, -B, -C, -DRB1 (low or high)\n",
        "    'hla_low_res_8', 'hla_high_res_8',\n",
        "    # Matching at HLA-A, -B, -C, -DRB1, -DQB1 (low or high)\n",
        "    'hla_low_res_10', 'hla_high_res_10'\n",
        "]\n",
        "\n",
        "OTHER_NUMERICAL_VARIABLES = ['year_hct', 'donor_age', 'age_at_hct', 'comorbidity_score', 'karnofsky_score']\n",
        "NUMERICAL_VARIABLES = HLA_COLUMNS + OTHER_NUMERICAL_VARIABLES\n",
        "\n",
        "TARGET_VARIABLES = ['efs_time', 'efs']\n",
        "ID_COLUMN = [\"ID\"]\n",
        "\n",
        "\n",
        "def preprocess_data(df):\n",
        "    df[CATEGORICAL_VARIABLES] = df[CATEGORICAL_VARIABLES].fillna(\"Unknown\")\n",
        "    df[OTHER_NUMERICAL_VARIABLES] = df[OTHER_NUMERICAL_VARIABLES].fillna(df[OTHER_NUMERICAL_VARIABLES].median())\n",
        "\n",
        "    return df\n",
        "\n",
        "train = preprocess_data(train)\n",
        "test = preprocess_data(test)\n",
        "\n",
        "\n",
        "def features_engineering(df):\n",
        "    # Change year_hct to relative year from 2000\n",
        "    df['year_hct'] = df['year_hct'] - 2000\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "train = features_engineering(train)\n",
        "test = features_engineering(test)\n",
        "\n",
        "train[CATEGORICAL_VARIABLES] = train[CATEGORICAL_VARIABLES].astype('category')\n",
        "test[CATEGORICAL_VARIABLES] = test[CATEGORICAL_VARIABLES].astype('category')\n",
        "\n",
        "FEATURES = train.drop(columns=['ID', 'efs', 'efs_time']).columns.tolist()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T15:54:18.081353Z",
          "iopub.execute_input": "2025-02-18T15:54:18.081678Z",
          "iopub.status.idle": "2025-02-18T15:54:19.459164Z",
          "shell.execute_reply.started": "2025-02-18T15:54:18.081647Z",
          "shell.execute_reply": "2025-02-18T15:54:19.458491Z"
        },
        "id": "vhVka-Cu8Wck"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "import xgboost\n",
        "print(\"Using XGBoost version\",xgboost.__version__)\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "FOLDS = 5\n",
        "kf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "oof_xgb = np.zeros(len(train))\n",
        "pred_efs = np.zeros(len(test))\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(kf.split(train, train[\"efs\"])):\n",
        "\n",
        "    print(\"#\"*25)\n",
        "    print(f\"### Fold {i+1}\")\n",
        "    print(\"#\"*25)\n",
        "\n",
        "    x_train = train.loc[train_index, FEATURES].copy()\n",
        "    y_train = train.loc[train_index, \"efs\"]\n",
        "    x_valid = train.loc[test_index, FEATURES].copy()\n",
        "    y_valid = train.loc[test_index, \"efs\"]\n",
        "    x_test = test[FEATURES].copy()\n",
        "\n",
        "    model_xgb = XGBClassifier(\n",
        "        device=\"cuda\",\n",
        "        max_depth=3,\n",
        "        colsample_bytree=0.7129400756425178,\n",
        "        subsample=0.8185881823156917,\n",
        "        n_estimators=20_000,\n",
        "        learning_rate=0.04425768131771064,\n",
        "        eval_metric=\"auc\",\n",
        "        early_stopping_rounds=50,\n",
        "        objective='binary:logistic',\n",
        "        scale_pos_weight=1.5379160847615545,\n",
        "        min_child_weight=4,\n",
        "        enable_categorical=True,\n",
        "        gamma=3.1330719334577584\n",
        "    )\n",
        "    model_xgb.fit(\n",
        "        x_train, y_train,\n",
        "        eval_set=[(x_valid, y_valid)],\n",
        "        verbose=100\n",
        "    )\n",
        "\n",
        "    # INFER OOF (Probabilities -> Binary)\n",
        "    oof_xgb[test_index] = (model_xgb.predict_proba(x_valid)[:, 1] > 0.5).astype(int)\n",
        "    # INFER TEST (Probabilities -> Average Probs)\n",
        "    pred_efs += model_xgb.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# COMPUTE AVERAGE TEST PREDS\n",
        "pred_efs = (pred_efs / FOLDS > 0.5).astype(int)\n",
        "\n",
        "# EVALUATE PERFORMANCE\n",
        "accuracy = accuracy_score(train[\"efs\"], oof_xgb)\n",
        "f1 = f1_score(train[\"efs\"], oof_xgb)\n",
        "roc_auc = roc_auc_score(train[\"efs\"], oof_xgb)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"ROC AUC Score: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T15:54:19.46088Z",
          "iopub.execute_input": "2025-02-18T15:54:19.461179Z",
          "iopub.status.idle": "2025-02-18T15:54:29.973563Z",
          "shell.execute_reply.started": "2025-02-18T15:54:19.461157Z",
          "shell.execute_reply": "2025-02-18T15:54:29.97287Z"
        },
        "id": "92rcPYv68Wck"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data\n",
        "\n",
        "Below are a few utility functions to load and prepare the data for training with pytorch."
      ],
      "metadata": {
        "id": "TK4N1JBb8Wcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from torch.utils.data import TensorDataset\n",
        "from warnings import filterwarnings\n",
        "\n",
        "filterwarnings('ignore')\n",
        "\n",
        "\n",
        "def get_X_cat(df, cat_cols, transformers=None):\n",
        "    \"\"\"\n",
        "    Apply a specific categorical data transformer or a LabelEncoder if None.\n",
        "    \"\"\"\n",
        "    if transformers is None:\n",
        "        transformers = [LabelEncoder().fit(df[col]) for col in cat_cols]\n",
        "    return transformers, np.array(\n",
        "        [transformer.transform(df[col]) for col, transformer in zip(cat_cols, transformers)]\n",
        "    ).T\n",
        "\n",
        "\n",
        "def preprocess_data(train, val):\n",
        "    \"\"\"\n",
        "    Standardize numerical variables and transform (Label-encode) categoricals.\n",
        "    Fill NA values with mean for numerical.\n",
        "    Create torch dataloaders to prepare data for training and evaluation.\n",
        "    \"\"\"\n",
        "    X_cat_train, X_cat_val, numerical, transformers = get_categoricals(train, val)\n",
        "    scaler = StandardScaler()\n",
        "    imp = SimpleImputer(missing_values=np.nan, strategy='mean', add_indicator=True)\n",
        "    X_num_train = imp.fit_transform(train[numerical])\n",
        "    X_num_train = scaler.fit_transform(X_num_train)\n",
        "    X_num_val = imp.transform(val[numerical])\n",
        "    X_num_val = scaler.transform(X_num_val)\n",
        "    dl_train = init_dl(X_cat_train, X_num_train, train, training=True)\n",
        "    dl_val = init_dl(X_cat_val, X_num_val, val)\n",
        "    return X_cat_val, X_num_train, X_num_val, dl_train, dl_val, transformers\n",
        "\n",
        "\n",
        "def get_categoricals(train, val):\n",
        "    \"\"\"\n",
        "    Remove constant categorical columns and transform them using LabelEncoder.\n",
        "    Return the label-transformers for each categorical column, categorical dataframes and numerical columns.\n",
        "    \"\"\"\n",
        "    categorical_cols, numerical = get_feature_types(train)\n",
        "    remove = []\n",
        "    for col in categorical_cols:\n",
        "        if train[col].nunique() == 1:\n",
        "            remove.append(col)\n",
        "        ind = ~val[col].isin(train[col])\n",
        "        if ind.any():\n",
        "            val.loc[ind, col] = np.nan\n",
        "    categorical_cols = [col for col in categorical_cols if col not in remove]\n",
        "    transformers, X_cat_train = get_X_cat(train, categorical_cols)\n",
        "    _, X_cat_val = get_X_cat(val, categorical_cols, transformers)\n",
        "    return X_cat_train, X_cat_val, numerical, transformers\n",
        "\n",
        "\n",
        "def init_dl(X_cat, X_num, df, training=False):\n",
        "    \"\"\"\n",
        "    Initialize data loaders with 4 dimensions : categorical dataframe, numerical dataframe and target values (efs and efs_time).\n",
        "    Notice that efs_time is log-transformed.\n",
        "    Fix batch size to 2048 and return dataloader for training or validation depending on training value.\n",
        "    \"\"\"\n",
        "    ds_train = TensorDataset(\n",
        "        torch.tensor(X_cat, dtype=torch.long),\n",
        "        torch.tensor(X_num, dtype=torch.float32),\n",
        "        torch.tensor(df.efs_time.values, dtype=torch.float32).log(),\n",
        "        torch.tensor(df.efs.values, dtype=torch.long)\n",
        "    )\n",
        "    bs = 2048\n",
        "    dl_train = torch.utils.data.DataLoader(ds_train, batch_size=bs, pin_memory=True, shuffle=training)\n",
        "    return dl_train\n",
        "\n",
        "\n",
        "def get_feature_types(train):\n",
        "    \"\"\"\n",
        "    Utility function to return categorical and numerical column names.\n",
        "    \"\"\"\n",
        "    categorical_cols = [col for i, col in enumerate(train.columns) if ((train[col].dtype == \"object\") | (2 < train[col].nunique() < 25))]\n",
        "    RMV = [\"ID\", \"efs\", \"efs_time\", \"y\"]\n",
        "    FEATURES = [c for c in train.columns if not c in RMV]\n",
        "    numerical = [i for i in FEATURES if i not in categorical_cols]\n",
        "    return categorical_cols, numerical\n",
        "\n",
        "\n",
        "def add_features(df):\n",
        "    \"\"\"\n",
        "    Create some new features to help the model focus on specific patterns.\n",
        "    \"\"\"\n",
        "    # sex_match = df.sex_match.astype(str)\n",
        "    # sex_match = sex_match.str.split(\"-\").str[0] == sex_match.str.split(\"-\").str[1]\n",
        "    # df['sex_match_bool'] = sex_match\n",
        "    # df.loc[df.sex_match.isna(), 'sex_match_bool'] = np.nan\n",
        "    # df['big_age'] = df.age_at_hct > 16\n",
        "    # df.loc[df.year_hct == 2019, 'year_hct'] = 2020\n",
        "    df['is_cyto_score_same'] = (df['cyto_score'] == df['cyto_score_detail']).astype(int)\n",
        "    # df['strange_age'] = df.age_at_hct == 0.044\n",
        "    # df['age_bin'] = pd.cut(df.age_at_hct, [0, 0.0441, 16, 30, 50, 100])\n",
        "    # df['age_ts'] = df.age_at_hct / df.donor_age\n",
        "    df['year_hct'] -= 2000\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Load data and add features.\n",
        "    \"\"\"\n",
        "    test = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")\n",
        "    test = add_features(test)\n",
        "    print(\"Test shape:\", test.shape)\n",
        "    train = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/train.csv\")\n",
        "    train = add_features(train)\n",
        "    print(\"Train shape:\", train.shape)\n",
        "    return test, train\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T15:54:29.97469Z",
          "iopub.execute_input": "2025-02-18T15:54:29.975051Z",
          "iopub.status.idle": "2025-02-18T15:54:33.60189Z",
          "shell.execute_reply.started": "2025-02-18T15:54:29.975029Z",
          "shell.execute_reply": "2025-02-18T15:54:33.601219Z"
        },
        "id": "KEg0T2xp8Wcl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define models with pairwise ranking loss\n",
        "\n",
        "The model is defined in 3 steps :\n",
        "* Embedding class for categorical data\n",
        "* MLP for numerical and categorical data\n",
        "* Final model trained with pairwise ranking loss with selection of valid pairs"
      ],
      "metadata": {
        "id": "sCEsnbwt8Wcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "from typing import List\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import numpy as np\n",
        "import torch\n",
        "from lifelines.utils import concordance_index\n",
        "from pytorch_lightning.cli import ReduceLROnPlateau\n",
        "from pytorch_tabular.models.common.layers import ODST\n",
        "from torch import nn\n",
        "from pytorch_lightning.utilities import grad_norm\n",
        "\n",
        "\n",
        "class CatEmbeddings(nn.Module):\n",
        "    \"\"\"\n",
        "    Embedding module for the categorical dataframe.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        projection_dim: int,\n",
        "        categorical_cardinality: List[int],\n",
        "        embedding_dim: int\n",
        "    ):\n",
        "        \"\"\"\n",
        "        projection_dim: The dimension of the final output after projecting the concatenated embeddings into a lower-dimensional space.\n",
        "        categorical_cardinality: A list where each element represents the number of unique categories (cardinality) in each categorical feature.\n",
        "        embedding_dim: The size of the embedding space for each categorical feature.\n",
        "        self.embeddings: list of embedding layers for each categorical feature.\n",
        "        self.projection: sequential neural network that goes from the embedding to the output projection dimension with GELU activation.\n",
        "        \"\"\"\n",
        "        super(CatEmbeddings, self).__init__()\n",
        "        self.embeddings = nn.ModuleList([\n",
        "            nn.Embedding(cardinality, embedding_dim)\n",
        "            for cardinality in categorical_cardinality\n",
        "        ])\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(embedding_dim * len(categorical_cardinality), projection_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(projection_dim, projection_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat):\n",
        "        \"\"\"\n",
        "        Apply the projection on concatened embeddings that contains all categorical features.\n",
        "        \"\"\"\n",
        "        x_cat = [embedding(x_cat[:, i]) for i, embedding in enumerate(self.embeddings)]\n",
        "        x_cat = torch.cat(x_cat, dim=1)\n",
        "        return self.projection(x_cat)\n",
        "\n",
        "\n",
        "class NN(nn.Module):\n",
        "    \"\"\"\n",
        "    Train a model on both categorical embeddings and numerical data.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            continuous_dim: int,\n",
        "            categorical_cardinality: List[int],\n",
        "            embedding_dim: int,\n",
        "            projection_dim: int,\n",
        "            hidden_dim: int,\n",
        "            dropout: float = 0\n",
        "    ):\n",
        "        \"\"\"\n",
        "        continuous_dim: The number of continuous features.\n",
        "        categorical_cardinality: A list of integers representing the number of unique categories in each categorical feature.\n",
        "        embedding_dim: The dimensionality of the embedding space for each categorical feature.\n",
        "        projection_dim: The size of the projected output space for the categorical embeddings.\n",
        "        hidden_dim: The number of neurons in the hidden layer of the MLP.\n",
        "        dropout: The dropout rate applied in the network.\n",
        "        self.embeddings: previous embeddings for categorical data.\n",
        "        self.mlp: defines an MLP model with an ODST layer followed by batch normalization and dropout.\n",
        "        self.out: linear output layer that maps the output of the MLP to a single value\n",
        "        self.dropout: defines dropout\n",
        "        Weights initialization with xavier normal algorithm and biases with zeros.\n",
        "        \"\"\"\n",
        "        super(NN, self).__init__()\n",
        "        self.embeddings = CatEmbeddings(projection_dim, categorical_cardinality, embedding_dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            ODST(projection_dim + continuous_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.out = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # initialize weights\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x_cat, x_cont):\n",
        "        \"\"\"\n",
        "        Create embedding layers for categorical data, concatenate with continous variables.\n",
        "        Add dropout and goes through MLP and return raw output and 1-dimensional output as well.\n",
        "        \"\"\"\n",
        "        x = self.embeddings(x_cat)\n",
        "        x = torch.cat([x, x_cont], dim=1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.mlp(x)\n",
        "        return self.out(x), x\n",
        "\n",
        "\n",
        "@functools.lru_cache\n",
        "def combinations(N):\n",
        "    \"\"\"\n",
        "    calculates all possible 2-combinations (pairs) of a tensor of indices from 0 to N-1,\n",
        "    and caches the result using functools.lru_cache for optimization\n",
        "    \"\"\"\n",
        "    ind = torch.arange(N)\n",
        "    comb = torch.combinations(ind, r=2)\n",
        "    return comb.cuda()\n",
        "\n",
        "\n",
        "class LitNN(pl.LightningModule):\n",
        "    \"\"\"\n",
        "    Main Model creation and losses definition to fully train the model.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            continuous_dim: int,\n",
        "            categorical_cardinality: List[int],\n",
        "            embedding_dim: int,\n",
        "            projection_dim: int,\n",
        "            hidden_dim: int,\n",
        "            lr: float = 1e-3,\n",
        "            dropout: float = 0.2,\n",
        "            weight_decay: float = 1e-3,\n",
        "            aux_weight: float = 0.1,\n",
        "            margin: float = 0.5,\n",
        "            race_index: int = 0\n",
        "    ):\n",
        "        \"\"\"\n",
        "        continuous_dim: The number of continuous input features.\n",
        "        categorical_cardinality: A list of integers, where each element corresponds to the number of unique categories for each categorical feature.\n",
        "        embedding_dim: The dimension of the embeddings for the categorical features.\n",
        "        projection_dim: The dimension of the projected space after embedding concatenation.\n",
        "        hidden_dim: The size of the hidden layers in the feedforward network (MLP).\n",
        "        lr: The learning rate for the optimizer.\n",
        "        dropout: Dropout probability to avoid overfitting.\n",
        "        weight_decay: The L2 regularization term for the optimizer.\n",
        "        aux_weight: Weight used for auxiliary tasks.\n",
        "        margin: Margin used in some loss functions.\n",
        "        race_index: An index that refer to race_group in the input data.\n",
        "        \"\"\"\n",
        "        super(LitNN, self).__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # Creates an instance of the NN model defined above\n",
        "        self.model = NN(\n",
        "            continuous_dim=self.hparams.continuous_dim,\n",
        "            categorical_cardinality=self.hparams.categorical_cardinality,\n",
        "            embedding_dim=self.hparams.embedding_dim,\n",
        "            projection_dim=self.hparams.projection_dim,\n",
        "            hidden_dim=self.hparams.hidden_dim,\n",
        "            dropout=self.hparams.dropout\n",
        "        )\n",
        "        self.targets = []\n",
        "\n",
        "        # Defines a small feedforward neural network that performs an auxiliary task with 1-dimensional output\n",
        "        self.aux_cls = nn.Sequential(\n",
        "            nn.Linear(self.hparams.hidden_dim, self.hparams.hidden_dim // 3),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.hparams.hidden_dim // 3, 1)\n",
        "        )\n",
        "\n",
        "    def on_before_optimizer_step(self, optimizer):\n",
        "        \"\"\"\n",
        "        Compute the 2-norm for each layer\n",
        "        If using mixed precision, the gradients are already unscaled here\n",
        "        \"\"\"\n",
        "        norms = grad_norm(self.model, norm_type=2)\n",
        "        self.log_dict(norms)\n",
        "\n",
        "    def forward(self, x_cat, x_cont):\n",
        "        \"\"\"\n",
        "        Forward pass that outputs the 1-dimensional prediction and the embeddings (raw output)\n",
        "        \"\"\"\n",
        "        x, emb = self.model(x_cat, x_cont)\n",
        "        return x.squeeze(1), emb\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        defines how the model processes each batch of data during training.\n",
        "        A batch is a combination of : categorical data, continuous data, efs_time (y) and efs event.\n",
        "        y_hat is the efs_time prediction on all data and aux_pred is auxiliary prediction on embeddings.\n",
        "        Calculates loss and race_group loss on full data.\n",
        "        Auxiliary loss is calculated with an event mask, ignoring efs=0 predictions and taking the average.\n",
        "        Returns loss and aux_loss multiplied by weight defined above.\n",
        "        \"\"\"\n",
        "        x_cat, x_cont, y, efs = batch\n",
        "        y_hat, emb = self(x_cat, x_cont)\n",
        "        aux_pred = self.aux_cls(emb).squeeze(1)\n",
        "        loss, race_loss = self.get_full_loss(efs, x_cat, y, y_hat)\n",
        "        aux_loss = nn.functional.mse_loss(aux_pred, y, reduction='none')\n",
        "        aux_mask = efs == 1\n",
        "        aux_loss = (aux_loss * aux_mask).sum() / aux_mask.sum()\n",
        "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.log(\"race_loss\", race_loss, on_epoch=True, prog_bar=True, logger=True, on_step=False)\n",
        "        self.log(\"aux_loss\", aux_loss, on_epoch=True, prog_bar=True, logger=True, on_step=False)\n",
        "        return loss + aux_loss * self.hparams.aux_weight\n",
        "\n",
        "    def get_full_loss(self, efs, x_cat, y, y_hat):\n",
        "        \"\"\"\n",
        "        Output loss and race_group loss.\n",
        "        \"\"\"\n",
        "        loss = self.calc_loss(y, y_hat, efs)\n",
        "        race_loss = self.get_race_losses(efs, x_cat, y, y_hat)\n",
        "        loss += 0.1 * race_loss\n",
        "        return loss, race_loss\n",
        "\n",
        "    def get_race_losses(self, efs, x_cat, y, y_hat):\n",
        "        \"\"\"\n",
        "        Calculate loss for each race_group based on deviation/variance.\n",
        "        \"\"\"\n",
        "        races = torch.unique(x_cat[:, self.hparams.race_index])\n",
        "        race_losses = []\n",
        "        for race in races:\n",
        "            ind = x_cat[:, self.hparams.race_index] == race\n",
        "            race_losses.append(self.calc_loss(y[ind], y_hat[ind], efs[ind]))\n",
        "        race_loss = sum(race_losses) / len(race_losses)\n",
        "        races_loss_std = sum((r - race_loss)**2 for r in race_losses) / len(race_losses)\n",
        "        return torch.sqrt(races_loss_std)\n",
        "\n",
        "    def calc_loss(self, y, y_hat, efs):\n",
        "        \"\"\"\n",
        "        Most important part of the model : loss function used for training.\n",
        "        We face survival data with event indicators along with time-to-event.\n",
        "\n",
        "        This function computes the main loss by the following the steps :\n",
        "        * create all data pairs with \"combinations\" function (= all \"two subjects\" combinations)\n",
        "        * make sure that we have at least 1 event in each pair\n",
        "        * convert y to +1 or -1 depending on the correct ranking\n",
        "        * loss is computed using a margin-based hinge loss\n",
        "        * mask is applied to ensure only valid pairs are being used (censored data can't be ranked with event in some cases)\n",
        "        * average loss on all pairs is returned\n",
        "        \"\"\"\n",
        "        N = y.shape[0]\n",
        "        comb = combinations(N)\n",
        "        comb = comb[(efs[comb[:, 0]] == 1) | (efs[comb[:, 1]] == 1)]\n",
        "        pred_left = y_hat[comb[:, 0]]\n",
        "        pred_right = y_hat[comb[:, 1]]\n",
        "        y_left = y[comb[:, 0]]\n",
        "        y_right = y[comb[:, 1]]\n",
        "        y = 2 * (y_left > y_right).int() - 1\n",
        "        loss = nn.functional.relu(-y * (pred_left - pred_right) + self.hparams.margin)\n",
        "        mask = self.get_mask(comb, efs, y_left, y_right)\n",
        "        loss = (loss.double() * (mask.double())).sum() / mask.sum()\n",
        "        return loss\n",
        "\n",
        "    def get_mask(self, comb, efs, y_left, y_right):\n",
        "        \"\"\"\n",
        "        Defines all invalid comparisons :\n",
        "        * Case 1: \"Left outlived Right\" but Right is censored\n",
        "        * Case 2: \"Right outlived Left\" but Left is censored\n",
        "        Masks for case 1 and case 2 are combined using |= operator and inverted using ~ to create a \"valid pair mask\"\n",
        "        \"\"\"\n",
        "        left_outlived = y_left >= y_right\n",
        "        left_1_right_0 = (efs[comb[:, 0]] == 1) & (efs[comb[:, 1]] == 0)\n",
        "        mask2 = (left_outlived & left_1_right_0)\n",
        "        right_outlived = y_right >= y_left\n",
        "        right_1_left_0 = (efs[comb[:, 1]] == 1) & (efs[comb[:, 0]] == 0)\n",
        "        mask2 |= (right_outlived & right_1_left_0)\n",
        "        mask2 = ~mask2\n",
        "        mask = mask2\n",
        "        return mask\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        This method defines how the model processes each batch during validation\n",
        "        \"\"\"\n",
        "        x_cat, x_cont, y, efs = batch\n",
        "        y_hat, emb = self(x_cat, x_cont)\n",
        "        loss, race_loss = self.get_full_loss(efs, x_cat, y, y_hat)\n",
        "        self.targets.append([y, y_hat.detach(), efs, x_cat[:, self.hparams.race_index]])\n",
        "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        \"\"\"\n",
        "        At the end of the validation epoch, it computes and logs the concordance index\n",
        "        \"\"\"\n",
        "        cindex, metric = self._calc_cindex()\n",
        "        self.log(\"cindex\", metric, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.log(\"cindex_simple\", cindex, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.targets.clear()\n",
        "\n",
        "    def _calc_cindex(self):\n",
        "        \"\"\"\n",
        "        Calculate c-index accounting for each race_group or global.\n",
        "        \"\"\"\n",
        "        y = torch.cat([t[0] for t in self.targets]).cpu().numpy()\n",
        "        y_hat = torch.cat([t[1] for t in self.targets]).cpu().numpy()\n",
        "        efs = torch.cat([t[2] for t in self.targets]).cpu().numpy()\n",
        "        races = torch.cat([t[3] for t in self.targets]).cpu().numpy()\n",
        "        metric = self._metric(efs, races, y, y_hat)\n",
        "        cindex = concordance_index(y, y_hat, efs)\n",
        "        return cindex, metric\n",
        "\n",
        "    def _metric(self, efs, races, y, y_hat):\n",
        "        \"\"\"\n",
        "        Calculate c-index accounting for each race_group\n",
        "        \"\"\"\n",
        "        metric_list = []\n",
        "        for race in np.unique(races):\n",
        "            y_ = y[races == race]\n",
        "            y_hat_ = y_hat[races == race]\n",
        "            efs_ = efs[races == race]\n",
        "            metric_list.append(concordance_index(y_, y_hat_, efs_))\n",
        "        metric = float(np.mean(metric_list) - np.sqrt(np.var(metric_list)))\n",
        "        return metric\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Same as training step but to log test data\n",
        "        \"\"\"\n",
        "        x_cat, x_cont, y, efs = batch\n",
        "        y_hat, emb = self(x_cat, x_cont)\n",
        "        loss, race_loss = self.get_full_loss(efs, x_cat, y, y_hat)\n",
        "        self.targets.append([y, y_hat.detach(), efs, x_cat[:, self.hparams.race_index]])\n",
        "        self.log(\"test_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def on_test_epoch_end(self) -> None:\n",
        "        \"\"\"\n",
        "        At the end of the test epoch, calculates and logs the concordance index for the test set\n",
        "        \"\"\"\n",
        "        cindex, metric = self._calc_cindex()\n",
        "        self.log(\"test_cindex\", metric, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.log(\"test_cindex_simple\", cindex, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.targets.clear()\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"\n",
        "        configures the optimizer and learning rate scheduler:\n",
        "        * Optimizer: Adam optimizer with weight decay (L2 regularization).\n",
        "        * Scheduler: Cosine Annealing scheduler, which adjusts the learning rate according to a cosine curve.\n",
        "        \"\"\"\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
        "        scheduler_config = {\n",
        "            \"scheduler\": torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "                optimizer,\n",
        "                T_max=45,\n",
        "                eta_min=6e-3\n",
        "            ),\n",
        "            \"interval\": \"epoch\",\n",
        "            \"frequency\": 1,\n",
        "            \"strict\": False,\n",
        "        }\n",
        "\n",
        "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler_config}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T15:54:33.60285Z",
          "iopub.execute_input": "2025-02-18T15:54:33.603254Z",
          "iopub.status.idle": "2025-02-18T15:54:40.957382Z",
          "shell.execute_reply.started": "2025-02-18T15:54:33.603199Z",
          "shell.execute_reply": "2025-02-18T15:54:40.956723Z"
        },
        "id": "JNtWk85f8Wcl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pytorch_lightning as pl\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, TQDMProgressBar\n",
        "from pytorch_lightning.callbacks import StochasticWeightAveraging\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "pl.seed_everything(42)\n",
        "\n",
        "def main(hparams):\n",
        "    \"\"\"\n",
        "    Main function to train the model.\n",
        "    The steps are as following :\n",
        "    * load data and fill efs and efs time for test data with 1\n",
        "    * initialize pred array with 0\n",
        "    * get categorical and numerical columns\n",
        "    * split the train data on the stratified criterion : race_group * newborns yes/no\n",
        "    * preprocess the fold data (create dataloaders)\n",
        "    * train the model and create final submission output\n",
        "    \"\"\"\n",
        "    test, train_original = load_data()\n",
        "    test['efs_time'] = 1\n",
        "    test['efs'] = 1\n",
        "    oof_nn_pairwise = np.zeros(len(train_original))\n",
        "    test_pred = np.zeros(test.shape[0])\n",
        "    categorical_cols, numerical = get_feature_types(train_original)\n",
        "    kf = StratifiedKFold(n_splits=5, shuffle=True, )\n",
        "    for i, (train_index, test_index) in enumerate(\n",
        "        kf.split(\n",
        "            train_original, train_original.race_group.astype(str) + (train_original.age_at_hct == 0.044).astype(str)\n",
        "        )\n",
        "    ):\n",
        "        tt = train_original.copy()\n",
        "        train = tt.iloc[train_index]\n",
        "        val = tt.iloc[test_index]\n",
        "        X_cat_val, X_num_train, X_num_val, dl_train, dl_val, transformers = preprocess_data(train, val)\n",
        "        model = train_final(X_num_train, dl_train, dl_val, transformers, categorical_cols=categorical_cols)\n",
        "        oof_pred, _ = model.cuda().eval()(\n",
        "            torch.tensor(X_cat_val, dtype=torch.long).cuda(),\n",
        "            torch.tensor(X_num_val, dtype=torch.float32).cuda()\n",
        "        )\n",
        "        oof_nn_pairwise[test_index] = oof_pred.detach().cpu().numpy()\n",
        "        # Create submission\n",
        "        train = tt.iloc[train_index]\n",
        "        X_cat_val, X_num_train, X_num_val, dl_train, dl_val, transformers = preprocess_data(train, test)\n",
        "        pred, _ = model.cuda().eval()(\n",
        "            torch.tensor(X_cat_val, dtype=torch.long).cuda(),\n",
        "            torch.tensor(X_num_val, dtype=torch.float32).cuda()\n",
        "        )\n",
        "        test_pred += pred.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "    return -test_pred, -oof_nn_pairwise\n",
        "\n",
        "\n",
        "\n",
        "def train_final(X_num_train, dl_train, dl_val, transformers, hparams=None, categorical_cols=None):\n",
        "    \"\"\"\n",
        "    Defines model hyperparameters and fit the model.\n",
        "    \"\"\"\n",
        "    if hparams is None:\n",
        "        hparams = {\n",
        "            \"embedding_dim\": 16,\n",
        "            \"projection_dim\": 112,\n",
        "            \"hidden_dim\": 56,\n",
        "            \"lr\": 0.06464861983337984,\n",
        "            \"dropout\": 0.05463240181423116,\n",
        "            \"aux_weight\": 0.26545778308743806,\n",
        "            \"margin\": 0.2588153271003354,\n",
        "            \"weight_decay\": 0.0002773544957610778\n",
        "        }\n",
        "    model = LitNN(\n",
        "        continuous_dim=X_num_train.shape[1],\n",
        "        categorical_cardinality=[len(t.classes_) for t in transformers],\n",
        "        race_index=categorical_cols.index(\"race_group\"),\n",
        "        **hparams\n",
        "    )\n",
        "    checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor=\"val_loss\", save_top_k=1)\n",
        "    trainer = pl.Trainer(\n",
        "        accelerator='cuda',\n",
        "        max_epochs=60,\n",
        "        log_every_n_steps=6,\n",
        "        callbacks=[\n",
        "            checkpoint_callback,\n",
        "            LearningRateMonitor(logging_interval='epoch'),\n",
        "            TQDMProgressBar(),\n",
        "            StochasticWeightAveraging(swa_lrs=1e-5, swa_epoch_start=45, annealing_epochs=15)\n",
        "        ],\n",
        "    )\n",
        "    trainer.fit(model, dl_train)\n",
        "    trainer.test(model, dl_val)\n",
        "    return model.eval()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T15:54:40.958078Z",
          "iopub.execute_input": "2025-02-18T15:54:40.958326Z",
          "iopub.status.idle": "2025-02-18T15:54:40.975343Z",
          "shell.execute_reply.started": "2025-02-18T15:54:40.958304Z",
          "shell.execute_reply": "2025-02-18T15:54:40.974631Z"
        },
        "id": "WIDBNuHp8Wcl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "hparams = None\n",
        "pairwise_ranking_pred, pairwise_ranking_oof = main(hparams)\n",
        "\n",
        "y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
        "y_pred = train[[\"ID\"]].copy()\n",
        "y_pred[\"prediction\"] = pairwise_ranking_oof\n",
        "m = score(y_true.copy(), y_pred.copy(), \"ID\")\n",
        "print(f\"\\nPairwise ranking NN CV =\",m)\n",
        "\n",
        "# Update predictions with classifier mask\n",
        "pairwise_ranking_oof[oof_xgb == 1] += 0.2\n",
        "y_pred[\"prediction\"] = pairwise_ranking_oof\n",
        "m = score(y_true.copy(), y_pred.copy(), \"ID\")\n",
        "print(f\"\\nPairwise ranking NN with classifier mask -> CV =\",m)\n",
        "\n",
        "pairwise_ranking_pred[pred_efs == 1] += 0.2"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T15:54:40.975981Z",
          "iopub.execute_input": "2025-02-18T15:54:40.976169Z",
          "iopub.status.idle": "2025-02-18T16:03:05.687433Z",
          "shell.execute_reply.started": "2025-02-18T15:54:40.976152Z",
          "shell.execute_reply": "2025-02-18T16:03:05.686691Z"
        },
        "id": "qs1p_jiR8Wcm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "subm_data = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/sample_submission.csv\")\n",
        "subm_data['prediction'] = pairwise_ranking_pred\n",
        "subm_data.to_csv('submission2.csv', index=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T16:03:05.689604Z",
          "iopub.execute_input": "2025-02-18T16:03:05.689833Z",
          "iopub.status.idle": "2025-02-18T16:03:05.704895Z",
          "shell.execute_reply.started": "2025-02-18T16:03:05.689814Z",
          "shell.execute_reply": "2025-02-18T16:03:05.704116Z"
        },
        "id": "_wl0ubz-8Wcm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "TFfoZFUO8Wcm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CIBMTR Yunbase**\n",
        "\n",
        "https://www.kaggle.com/code/yunsuxiaozi/cibmtr-yunbase"
      ],
      "metadata": {
        "id": "Aesh_LMF8Wcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --requirement /kaggle/input/yunbase/Yunbase/requirements.txt  \\\n",
        "--no-index --find-links file:/kaggle/input/yunbase/\n",
        "\n",
        "!pip install -q /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\n",
        "!pip install -q /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\n",
        "!pip install -q /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\n",
        "!pip install -q /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\n",
        "!pip install -q /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T16:03:05.706429Z",
          "iopub.execute_input": "2025-02-18T16:03:05.706644Z",
          "iopub.status.idle": "2025-02-18T16:03:28.629917Z",
          "shell.execute_reply.started": "2025-02-18T16:03:05.706624Z",
          "shell.execute_reply": "2025-02-18T16:03:28.628884Z"
        },
        "id": "cYAM1tH38Wcm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "source_file_path = '/kaggle/input/yunbase/Yunbase/baseline.py'\n",
        "target_file_path = '/kaggle/working/baseline.py'\n",
        "with open(source_file_path, 'r', encoding='utf-8') as file:\n",
        "    content = file.read()\n",
        "with open(target_file_path, 'w', encoding='utf-8') as file:\n",
        "    file.write(content)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T16:03:28.630996Z",
          "iopub.execute_input": "2025-02-18T16:03:28.631344Z",
          "iopub.status.idle": "2025-02-18T16:03:28.642514Z",
          "shell.execute_reply.started": "2025-02-18T16:03:28.631306Z",
          "shell.execute_reply": "2025-02-18T16:03:28.641691Z"
        },
        "id": "p7rzKyyL8Wcm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from baseline import Yunbase\n",
        "import pandas as pd#read csv,parquet\n",
        "import numpy as np#for scientific computation of matrices\n",
        "from  lightgbm import LGBMRegressor,LGBMClassifier,log_evaluation,early_stopping\n",
        "from catboost import CatBoostRegressor,CatBoostClassifier\n",
        "from xgboost import XGBRegressor,XGBClassifier\n",
        "from lifelines import KaplanMeierFitter\n",
        "import warnings#avoid some negligible errors\n",
        "#The filterwarnings () method is used to set warning filters, which can control the output method and level of warning information.\n",
        "warnings.filterwarnings('ignore')\n",
        "import random#provide some function to generate random_seed.\n",
        "#set random seed,to make sure model can be recurrented.\n",
        "def seed_everything(seed):\n",
        "    np.random.seed(seed)#numpy's random seed\n",
        "    random.seed(seed)#python built-in random seed\n",
        "seed_everything(seed=2025)\n",
        "\n",
        "train=pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/train.csv\")\n",
        "test=pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")\n",
        "train_solution=train[['ID','efs','efs_time','race_group']].copy()\n",
        "\n",
        "def logit(p):\n",
        "    return np.log(p) - np.log(1 - p)\n",
        "max_efs_time,min_efs_time=80,-100\n",
        "train['efs_time']=train['efs_time']/(max_efs_time-min_efs_time)\n",
        "train['efs_time']=train['efs_time'].apply(lambda x:logit(x))\n",
        "train['efs_time']+=10\n",
        "print(train['efs_time'].max(),train['efs_time'].min())\n",
        "\n",
        "race2weight={'American Indian or Alaska Native':0.68,\n",
        "'Asian':0.7,'Black or African-American':0.67,\n",
        "'More than one race':0.68,\n",
        "'Native Hawaiian or other Pacific Islander':0.66,\n",
        "'White':0.64}\n",
        "train['weight']=0.5*train['efs']+0.5\n",
        "train['raceweight']=train['race_group'].apply(lambda x:race2weight.get(x,1))\n",
        "train['weight']=train['weight']/train['raceweight']\n",
        "train.drop(['raceweight'],axis=1,inplace=True)\n",
        "\n",
        "train.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T16:03:28.643448Z",
          "iopub.execute_input": "2025-02-18T16:03:28.643742Z",
          "iopub.status.idle": "2025-02-18T16:04:01.396021Z",
          "shell.execute_reply.started": "2025-02-18T16:03:28.643715Z",
          "shell.execute_reply": "2025-02-18T16:04:01.395077Z"
        },
        "id": "Ie6RJOrb8Wcm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "def transform_survival_probability(df, time_col='efs_time', event_col='efs'):\n",
        "\n",
        "    kmf = KaplanMeierFitter()\n",
        "\n",
        "    kmf.fit(df[time_col], event_observed=df[event_col])\n",
        "\n",
        "    survival_probabilities = kmf.survival_function_at_times(df[time_col]).values.flatten()\n",
        "\n",
        "    return survival_probabilities\n",
        "\n",
        "race_group=sorted(train['race_group'].unique())\n",
        "for race in race_group:\n",
        "    train.loc[train['race_group']==race,\"target\"] = transform_survival_probability(train[train['race_group']==race], time_col='efs_time', event_col='efs')\n",
        "    gap=0.7*(train.loc[(train['race_group']==race)&(train['efs']==0)]['target'].max()-train.loc[(train['race_group']==race)&(train['efs']==1)]['target'].min())/2\n",
        "    train.loc[(train['race_group']==race)&(train['efs']==0),'target']-=gap\n",
        "\n",
        "sns.histplot(data=train, x='target', hue='efs', element='step', stat='density', common_norm=False)\n",
        "plt.legend(title='efs')\n",
        "plt.title('Distribution of Target by EFS')\n",
        "plt.xlabel('Target')\n",
        "plt.ylabel('Density')\n",
        "plt.show()\n",
        "\n",
        "train.drop(['efs','efs_time'],axis=1,inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T16:04:01.397025Z",
          "iopub.execute_input": "2025-02-18T16:04:01.397367Z",
          "iopub.status.idle": "2025-02-18T16:04:01.974105Z",
          "shell.execute_reply.started": "2025-02-18T16:04:01.397343Z",
          "shell.execute_reply": "2025-02-18T16:04:01.973431Z"
        },
        "id": "xYIuKvNb8Wcm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#nunique=2\n",
        "nunique2=[col for col in train.columns if train[col].nunique()==2 and col!='efs']\n",
        "#nunique<50\n",
        "nunique50=[col for col in train.columns if train[col].nunique()<50 and col not in ['efs','weight']]+['age_group','dri_score_NA']\n",
        "\n",
        "def FE(df):\n",
        "    print(\"< deal with outlier >\")\n",
        "    df['nan_value_each_row'] = df.isnull().sum(axis=1)\n",
        "    #year_hct=2020 only 4 rows.\n",
        "    df['year_hct']=df['year_hct'].replace(2020,2019)\n",
        "    df['age_group']=df['age_at_hct']//10\n",
        "    #karnofsky_score 40 only 10 rows.\n",
        "    df['karnofsky_score']=df['karnofsky_score'].replace(40,50)\n",
        "    #hla_high_res_8=2 only 2 rows.\n",
        "    df['hla_high_res_8']=df['hla_high_res_8'].replace(2,3)\n",
        "    #hla_high_res_6=0 only 1 row.\n",
        "    df['hla_high_res_6']=df['hla_high_res_6'].replace(0,2)\n",
        "    #hla_high_res_10=3 only 1 row.\n",
        "    df['hla_high_res_10']=df['hla_high_res_10'].replace(3,4)\n",
        "    #hla_low_res_8=2 only 1 row.\n",
        "    df['hla_low_res_8']=df['hla_low_res_8'].replace(2,3)\n",
        "    df['dri_score']=df['dri_score'].replace('Missing disease status','N/A - disease not classifiable')\n",
        "    df['dri_score_NA']=df['dri_score'].apply(lambda x:int('N/A' in str(x)))\n",
        "    for col in ['diabetes','pulm_moderate','cardiac']:\n",
        "        df.loc[df[col].isna(),col]='Not done'\n",
        "\n",
        "    print(\"< cross feature >\")\n",
        "    df['donor_age-age_at_hct']=df['donor_age']-df['age_at_hct']\n",
        "    df['comorbidity_score+karnofsky_score']=df['comorbidity_score']+df['karnofsky_score']\n",
        "    df['comorbidity_score-karnofsky_score']=df['comorbidity_score']-df['karnofsky_score']\n",
        "    df['comorbidity_score*karnofsky_score']=df['comorbidity_score']*df['karnofsky_score']\n",
        "    df['comorbidity_score/karnofsky_score']=df['comorbidity_score']/df['karnofsky_score']\n",
        "\n",
        "    print(\"< fillna >\")\n",
        "    df[nunique50]=df[nunique50].astype(str).fillna('NaN')\n",
        "\n",
        "    print(\"< combine category feature >\")\n",
        "    for i in range(len(nunique2)):\n",
        "        for j in range(i+1,len(nunique2)):\n",
        "            df[nunique2[i]+nunique2[j]]=df[nunique2[i]].astype(str)+df[nunique2[j]].astype(str)\n",
        "\n",
        "    print(\"< drop useless columns >\")\n",
        "    df.drop(['ID'],axis=1,inplace=True,errors='ignore')\n",
        "    return df\n",
        "\n",
        "combine_category_cols=[]\n",
        "for i in range(len(nunique2)):\n",
        "    for j in range(i+1,len(nunique2)):\n",
        "        combine_category_cols.append(nunique2[i]+nunique2[j])\n",
        "\n",
        "total_category_feature=nunique50+combine_category_cols\n",
        "\n",
        "target_stat=[]\n",
        "for j in range(len(total_category_feature)):\n",
        "   for col in ['donor_age','age_at_hct','target']:\n",
        "    target_stat.append( (total_category_feature[j],col,['count','mean','max','std','skew']) )\n",
        "\n",
        "num_folds=10\n",
        "\n",
        "lgb_params={\"boosting_type\": \"gbdt\",\"metric\": 'mae',\n",
        "            'random_state': 2025,  \"max_depth\": 9,\"learning_rate\": 0.1,\n",
        "            \"n_estimators\": 768,\"colsample_bytree\": 0.6,\"colsample_bynode\": 0.6,\n",
        "            \"verbose\": -1,\"reg_alpha\": 0.2,\n",
        "            \"reg_lambda\": 5,\"extra_trees\":True,'num_leaves':64,\"max_bin\":255,\n",
        "            'importance_type': 'gain',#better than 'split'\n",
        "            'device':'gpu','gpu_use_dp':True\n",
        "           }\n",
        "\n",
        "cat_params={'random_state':2025,'eval_metric' : 'MAE',\n",
        "            'bagging_temperature': 0.50,'iterations': 650,\n",
        "            'learning_rate': 0.1,'max_depth': 8,\n",
        "            'l2_leaf_reg': 1.25,'min_data_in_leaf': 24,\n",
        "            'random_strength' : 0.25, 'verbose': 0,\n",
        "            'task_type':'GPU',\n",
        "            }\n",
        "# xgb_params={'random_state': 2025, 'n_estimators': 256,\n",
        "#             'learning_rate': 0.1, 'max_depth': 6,\n",
        "#             'reg_alpha': 0.08, 'reg_lambda': 0.8,\n",
        "#             'subsample': 0.95, 'colsample_bytree': 0.6,\n",
        "#             'min_child_weight': 3,'early_stopping_rounds':1024,\n",
        "#              'enable_categorical':True,'tree_method':'gpu_hist'\n",
        "#             }\n",
        "\n",
        "yunbase=Yunbase(num_folds=num_folds,\n",
        "                  models=[(LGBMRegressor(**lgb_params),'lgb'),\n",
        "                          (CatBoostRegressor(**cat_params),'cat'),\n",
        "                          # (XGBRegressor(**xgb_params),'xgb')\n",
        "                         ],\n",
        "                  FE=FE,\n",
        "                  seed=2025,\n",
        "                  objective='regression',\n",
        "                  metric='mae',\n",
        "                  target_col='target',\n",
        "                  device='gpu',\n",
        "                  one_hot_max=-1,\n",
        "                  early_stop=1000,\n",
        "                  cross_cols=['donor_age','age_at_hct'],\n",
        "                  target_stat=target_stat,\n",
        "                  use_data_augmentation=True,\n",
        "                  use_scaler=True,\n",
        "                  log=250,\n",
        "                  plot_feature_importance=True,\n",
        "                  #print metric score when model training\n",
        "                  use_eval_metric=False,\n",
        ")\n",
        "yunbase.fit(train,category_cols=nunique2)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T16:04:01.974986Z",
          "iopub.execute_input": "2025-02-18T16:04:01.975326Z",
          "iopub.status.idle": "2025-02-18T16:54:04.135982Z",
          "shell.execute_reply.started": "2025-02-18T16:04:01.975292Z",
          "shell.execute_reply": "2025-02-18T16:54:04.135091Z"
        },
        "id": "ijrIGeUi8Wcm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas.api.types\n",
        "from lifelines.utils import concordance_index\n",
        "\n",
        "class ParticipantVisibleError(Exception):\n",
        "    pass\n",
        "\n",
        "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
        "\n",
        "    del solution[row_id_column_name]\n",
        "    del submission[row_id_column_name]\n",
        "\n",
        "    event_label = 'efs'\n",
        "    interval_label = 'efs_time'\n",
        "    prediction_label = 'prediction'\n",
        "    for col in submission.columns:\n",
        "        if not pandas.api.types.is_numeric_dtype(submission[col]):\n",
        "            raise ParticipantVisibleError(f'Submission column {col} must be a number')\n",
        "    # Merging solution and submission dfs on ID\n",
        "    merged_df = pd.concat([solution, submission], axis=1)\n",
        "    merged_df.reset_index(inplace=True)\n",
        "    merged_df_race_dict = dict(merged_df.groupby(['race_group']).groups)\n",
        "    metric_list = []\n",
        "    for race in merged_df_race_dict.keys():\n",
        "        # Retrieving values from y_test based on index\n",
        "        indices = sorted(merged_df_race_dict[race])\n",
        "        merged_df_race = merged_df.iloc[indices]\n",
        "        # Calculate the concordance index\n",
        "        c_index_race = concordance_index(\n",
        "                        merged_df_race[interval_label],\n",
        "                        -merged_df_race[prediction_label],\n",
        "                        merged_df_race[event_label])\n",
        "        metric_list.append(c_index_race)\n",
        "    return float(np.mean(metric_list)-np.sqrt(np.var(metric_list)))\n",
        "\n",
        "weights = [0.5,0.5]\n",
        "\n",
        "lgb_prediction=np.load(f\"Yunbase_info/lgb_seed{yunbase.seed}_repeat0_fold{yunbase.num_folds}_{yunbase.target_col}.npy\")\n",
        "lgb_prediction=pd.DataFrame({'ID':train_solution['ID'],'prediction':lgb_prediction})\n",
        "print(f\"lgb_score:{score(train_solution.copy(),lgb_prediction.copy(),row_id_column_name='ID')}\")\n",
        "# xgb_prediction=np.load(f\"Yunbase_info/xgb_seed{yunbase.seed}_repeat0_fold{yunbase.num_folds}_{yunbase.target_col}.npy\")\n",
        "# xgb_prediction=pd.DataFrame({'ID':train_solution['ID'],'prediction':xgb_prediction})\n",
        "# print(f\"xgb_score:{score(train_solution.copy(),xgb_prediction.copy(),row_id_column_name='ID')}\")\n",
        "cat_prediction=np.load(f\"Yunbase_info/cat_seed{yunbase.seed}_repeat0_fold{yunbase.num_folds}_{yunbase.target_col}.npy\")\n",
        "cat_prediction=pd.DataFrame({'ID':train_solution['ID'],'prediction':cat_prediction})\n",
        "print(f\"cat_score:{score(train_solution.copy(),cat_prediction.copy(),row_id_column_name='ID')}\")\n",
        "\n",
        "y_preds=[\n",
        "    lgb_prediction.copy(),\n",
        "    # xgb_prediction.copy(),\n",
        "    cat_prediction.copy()\n",
        "]\n",
        "\n",
        "final_prediction=lgb_prediction.copy()\n",
        "final_prediction['prediction']=0\n",
        "for i in range(len(y_preds)):\n",
        "    final_prediction['prediction']+=weights[i]*y_preds[i]['prediction']\n",
        "metric=score(train_solution.copy(),final_prediction.copy(),row_id_column_name='ID')\n",
        "print(f\"final_CV:{metric}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T16:54:04.136879Z",
          "iopub.execute_input": "2025-02-18T16:54:04.137141Z",
          "iopub.status.idle": "2025-02-18T16:54:05.444711Z",
          "shell.execute_reply.started": "2025-02-18T16:54:04.137118Z",
          "shell.execute_reply": "2025-02-18T16:54:05.443916Z"
        },
        "id": "D4leJsld8Wcm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds=yunbase.predict(test,weights=weights)\n",
        "yunbase.target_col='prediction'\n",
        "yunbase.submit(\"/kaggle/input/equity-post-HCT-survival-predictions/sample_submission.csv\",test_preds,\n",
        "               save_name='submission1'\n",
        "              )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T16:54:05.44561Z",
          "iopub.execute_input": "2025-02-18T16:54:05.445868Z",
          "iopub.status.idle": "2025-02-18T16:58:40.776601Z",
          "shell.execute_reply.started": "2025-02-18T16:54:05.445845Z",
          "shell.execute_reply": "2025-02-18T16:58:40.775618Z"
        },
        "id": "XvhsQhwf8Wcm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CIBMTR | EDA & Ensemble Model**\n",
        "\n",
        "https://www.kaggle.com/code/andreasbis/cibmtr-eda-ensemble-model"
      ],
      "metadata": {
        "id": "PuIqFmkM8Wcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\n",
        "!pip install /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\n",
        "!pip install /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\n",
        "!pip install /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\n",
        "!pip install /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T16:58:40.777737Z",
          "iopub.execute_input": "2025-02-18T16:58:40.778105Z",
          "iopub.status.idle": "2025-02-18T16:58:59.653358Z",
          "shell.execute_reply.started": "2025-02-18T16:58:40.778064Z",
          "shell.execute_reply": "2025-02-18T16:58:59.652247Z"
        },
        "id": "Zl42BsQx8Wcm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from pathlib import Path\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "import pandas as pd\n",
        "import plotly.colors as pc\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = 'iframe'\n",
        "\n",
        "pd.options.display.max_columns = None\n",
        "\n",
        "from lifelines import CoxPHFitter\n",
        "from lifelines import KaplanMeierFitter\n",
        "from lifelines import NelsonAalenFitter\n",
        "import lightgbm as lgb\n",
        "from metric import score\n",
        "from scipy.stats import rankdata\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T16:58:59.655411Z",
          "iopub.execute_input": "2025-02-18T16:58:59.65569Z",
          "iopub.status.idle": "2025-02-18T16:59:00.735566Z",
          "shell.execute_reply.started": "2025-02-18T16:58:59.655666Z",
          "shell.execute_reply": "2025-02-18T16:59:00.734842Z"
        },
        "id": "141gvp_B8Wcm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "\n",
        "    train_path = Path('/kaggle/input/equity-post-HCT-survival-predictions/train.csv')\n",
        "    test_path = Path('/kaggle/input/equity-post-HCT-survival-predictions/test.csv')\n",
        "    subm_path = Path('/kaggle/input/equity-post-HCT-survival-predictions/sample_submission.csv')\n",
        "\n",
        "    colorscale = 'Redor'\n",
        "    color = '#A2574F'\n",
        "\n",
        "    batch_size = 32768\n",
        "    early_stop = 300\n",
        "    penalizer = 0.01\n",
        "    n_splits = 5\n",
        "\n",
        "    weights = [2, 1, 6, 3, 6, 3, 6, 6]\n",
        "\n",
        "    ctb_params = {\n",
        "        'loss_function': 'RMSE',\n",
        "        'learning_rate': 0.03,\n",
        "        'random_state': 42,\n",
        "        'task_type': 'CPU',\n",
        "        'num_trees': 6000,\n",
        "        'reg_lambda': 8.0,\n",
        "        'depth': 8\n",
        "    }\n",
        "\n",
        "    lgb_params = {\n",
        "        'objective': 'regression',\n",
        "        'min_child_samples': 32,\n",
        "        'num_iterations': 6000,\n",
        "        'learning_rate': 0.03,\n",
        "        'extra_trees': True,\n",
        "        'reg_lambda': 8.0,\n",
        "        'reg_alpha': 0.1,\n",
        "        'num_leaves': 64,\n",
        "        'metric': 'rmse',\n",
        "        'max_depth': 8,\n",
        "        'device': 'cpu',\n",
        "        'max_bin': 128,\n",
        "        'verbose': -1,\n",
        "        'seed': 42\n",
        "    }\n",
        "\n",
        "    cox1_params = {\n",
        "        'grow_policy': 'Depthwise',\n",
        "        'min_child_samples': 8,\n",
        "        'loss_function': 'Cox',\n",
        "        'learning_rate': 0.03,\n",
        "        'random_state': 42,\n",
        "        'task_type': 'CPU',\n",
        "        'num_trees': 6000,\n",
        "        'reg_lambda': 8.0,\n",
        "        'depth': 8\n",
        "    }\n",
        "\n",
        "    cox2_params = {\n",
        "        'grow_policy': 'Lossguide',\n",
        "        'min_child_samples': 2,\n",
        "        'loss_function': 'Cox',\n",
        "        'learning_rate': 0.03,\n",
        "        'random_state': 42,\n",
        "        'task_type': 'CPU',\n",
        "        'num_trees': 6000,\n",
        "        'reg_lambda': 8.0,\n",
        "        'num_leaves': 32,\n",
        "        'depth': 8\n",
        "    }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T16:59:00.736416Z",
          "iopub.execute_input": "2025-02-18T16:59:00.736653Z",
          "iopub.status.idle": "2025-02-18T16:59:00.742969Z",
          "shell.execute_reply.started": "2025-02-18T16:59:00.736632Z",
          "shell.execute_reply": "2025-02-18T16:59:00.742323Z"
        },
        "id": "9M8i5jp68Wcm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class FE:\n",
        "\n",
        "    def __init__(self, batch_size):\n",
        "        self._batch_size = batch_size\n",
        "\n",
        "    def _load_data(self, path):\n",
        "\n",
        "        return pl.read_csv(path, batch_size=self._batch_size)\n",
        "\n",
        "    def _update_hla_columns(self, df):\n",
        "\n",
        "        df = df.with_columns(\n",
        "\n",
        "            pl.col('hla_match_a_low').fill_null(0)\n",
        "            .add(pl.col('hla_match_b_low').fill_null(0))\n",
        "            .add(pl.col('hla_match_drb1_high').fill_null(0))\n",
        "            .alias('hla_nmdp_6'),\n",
        "\n",
        "            pl.col('hla_match_a_low').fill_null(0)\n",
        "            .add(pl.col('hla_match_b_low').fill_null(0))\n",
        "            .add(pl.col('hla_match_drb1_low').fill_null(0))\n",
        "            .alias('hla_low_res_6'),\n",
        "\n",
        "            pl.col('hla_match_a_high').fill_null(0)\n",
        "            .add(pl.col('hla_match_b_high').fill_null(0))\n",
        "            .add(pl.col('hla_match_drb1_high').fill_null(0))\n",
        "            .alias('hla_high_res_6'),\n",
        "\n",
        "            pl.col('hla_match_a_low').fill_null(0)\n",
        "            .add(pl.col('hla_match_b_low').fill_null(0))\n",
        "            .add(pl.col('hla_match_c_low').fill_null(0))\n",
        "            .add(pl.col('hla_match_drb1_low').fill_null(0))\n",
        "            .alias('hla_low_res_8'),\n",
        "\n",
        "            pl.col('hla_match_a_high').fill_null(0)\n",
        "            .add(pl.col('hla_match_b_high').fill_null(0))\n",
        "            .add(pl.col('hla_match_c_high').fill_null(0))\n",
        "            .add(pl.col('hla_match_drb1_high').fill_null(0))\n",
        "            .alias('hla_high_res_8'),\n",
        "\n",
        "            pl.col('hla_match_a_low').fill_null(0)\n",
        "            .add(pl.col('hla_match_b_low').fill_null(0))\n",
        "            .add(pl.col('hla_match_c_low').fill_null(0))\n",
        "            .add(pl.col('hla_match_drb1_low').fill_null(0))\n",
        "            .add(pl.col('hla_match_dqb1_low').fill_null(0))\n",
        "            .alias('hla_low_res_10'),\n",
        "\n",
        "            pl.col('hla_match_a_high').fill_null(0)\n",
        "            .add(pl.col('hla_match_b_high').fill_null(0))\n",
        "            .add(pl.col('hla_match_c_high').fill_null(0))\n",
        "            .add(pl.col('hla_match_drb1_high').fill_null(0))\n",
        "            .add(pl.col('hla_match_dqb1_high').fill_null(0))\n",
        "            .alias('hla_high_res_10'),\n",
        "\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _cast_datatypes(self, df):\n",
        "\n",
        "        num_cols = [\n",
        "            'hla_high_res_8',\n",
        "            'hla_low_res_8',\n",
        "            'hla_high_res_6',\n",
        "            'hla_low_res_6',\n",
        "            'hla_high_res_10',\n",
        "            'hla_low_res_10',\n",
        "            'hla_match_dqb1_high',\n",
        "            'hla_match_dqb1_low',\n",
        "            'hla_match_drb1_high',\n",
        "            'hla_match_drb1_low',\n",
        "            'hla_nmdp_6',\n",
        "            'year_hct',\n",
        "            'hla_match_a_high',\n",
        "            'hla_match_a_low',\n",
        "            'hla_match_b_high',\n",
        "            'hla_match_b_low',\n",
        "            'hla_match_c_high',\n",
        "            'hla_match_c_low',\n",
        "            'donor_age',\n",
        "            'age_at_hct',\n",
        "            'comorbidity_score',\n",
        "            'karnofsky_score',\n",
        "            'efs',\n",
        "            'efs_time'\n",
        "        ]\n",
        "\n",
        "        for col in df.columns:\n",
        "\n",
        "            if col in num_cols:\n",
        "                df = df.with_columns(pl.col(col).fill_null(-1).cast(pl.Float32))\n",
        "\n",
        "            else:\n",
        "                df = df.with_columns(pl.col(col).fill_null('Unknown').cast(pl.String))\n",
        "\n",
        "        return df.with_columns(pl.col('ID').cast(pl.Int32))\n",
        "\n",
        "    def info(self, df):\n",
        "\n",
        "        print(f'\\nShape of dataframe: {df.shape}')\n",
        "\n",
        "        mem = df.memory_usage().sum() / 1024**2\n",
        "        print('Memory usage: {:.2f} MB\\n'.format(mem))\n",
        "\n",
        "        display(df.head())\n",
        "\n",
        "    def apply_fe(self, path):\n",
        "\n",
        "        df = self._load_data(path)\n",
        "        df = self._update_hla_columns(df)\n",
        "        df = self._cast_datatypes(df)\n",
        "        df = df.to_pandas()\n",
        "        self.info(df)\n",
        "\n",
        "        cat_cols = [col for col in df.columns if df[col].dtype == pl.String]\n",
        "\n",
        "        return df, cat_cols\n",
        "\n",
        "fe = FE(CFG.batch_size)\n",
        "train_data, cat_cols = fe.apply_fe(CFG.train_path)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T16:59:00.743919Z",
          "iopub.execute_input": "2025-02-18T16:59:00.744178Z",
          "iopub.status.idle": "2025-02-18T16:59:01.109096Z",
          "shell.execute_reply.started": "2025-02-18T16:59:00.744152Z",
          "shell.execute_reply": "2025-02-18T16:59:01.108318Z"
        },
        "id": "bUnvGu-g8Wcm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_data, _ = fe.apply_fe(CFG.test_path)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T16:59:01.109946Z",
          "iopub.execute_input": "2025-02-18T16:59:01.110179Z",
          "iopub.status.idle": "2025-02-18T16:59:01.161835Z",
          "shell.execute_reply.started": "2025-02-18T16:59:01.110159Z",
          "shell.execute_reply": "2025-02-18T16:59:01.161113Z"
        },
        "id": "gcD8whdb8Wcm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class EDA:\n",
        "\n",
        "    def __init__(self, colorscale, color, data):\n",
        "        self._colorscale = colorscale\n",
        "        self._color = color\n",
        "        self.data = data\n",
        "\n",
        "    def _template(self, fig, title):\n",
        "\n",
        "        fig.update_layout(\n",
        "            title=title,\n",
        "            title_x=0.5,\n",
        "            plot_bgcolor='rgba(247, 230, 202, 1)',\n",
        "            paper_bgcolor='rgba(247, 230, 202, 1)',\n",
        "            font=dict(color=self._color),\n",
        "            margin=dict(l=72, r=72, t=72, b=72),\n",
        "            height=720\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def distribution_plot(self, col, title):\n",
        "\n",
        "        fig = px.histogram(\n",
        "            self.data,\n",
        "            x=col,\n",
        "            nbins=100,\n",
        "            color_discrete_sequence=[self._color]\n",
        "        )\n",
        "\n",
        "        fig.update_layout(\n",
        "            xaxis_title='Values',\n",
        "            yaxis_title='Count',\n",
        "            bargap=0.1,\n",
        "            xaxis=dict(gridcolor='grey'),\n",
        "            yaxis=dict(gridcolor='grey', zerolinecolor='grey')\n",
        "        )\n",
        "\n",
        "        fig.update_traces(hovertemplate='Value: %{x:.2f}<br>Count: %{y:,}')\n",
        "\n",
        "        fig = self._template(fig, f'{title}')\n",
        "        fig.show()\n",
        "\n",
        "    def bar_chart(self, col):\n",
        "\n",
        "        value_counts = self.data[col].value_counts().reset_index()\n",
        "        value_counts.columns = [col, 'count']\n",
        "\n",
        "        fig = px.bar(\n",
        "            value_counts,\n",
        "            y=col,\n",
        "            x='count',\n",
        "            orientation='h',\n",
        "            color='count',\n",
        "            color_continuous_scale=self._colorscale,\n",
        "        )\n",
        "\n",
        "        fig.update_layout(\n",
        "            xaxis_title='Count',\n",
        "            yaxis_title='',\n",
        "            xaxis=dict(gridcolor='grey'),\n",
        "            yaxis=dict(gridcolor='grey', zerolinecolor='grey')\n",
        "        )\n",
        "\n",
        "        fig.update_traces(\n",
        "            hovertemplate=(\n",
        "                f'<b>{col}:</b> %{{y}}<br>'\n",
        "                '<b>Count:</b> %{x:,}<br>'\n",
        "            ),\n",
        "            hoverlabel=dict(\n",
        "                font=dict(color=self._color),\n",
        "                bgcolor='rgba(247, 230, 202, 1)'\n",
        "            )\n",
        "        )\n",
        "\n",
        "        fig = self._template(fig, f'{col}')\n",
        "        fig.show()\n",
        "\n",
        "    def _plot_cv(self, scores, title, metric='Stratified C-Index'):\n",
        "\n",
        "        fold_scores = [round(score, 3) for score in scores]\n",
        "        mean_score = round(np.mean(scores), 3)\n",
        "\n",
        "        fig = go.Figure()\n",
        "\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x = list(range(1, len(fold_scores) + 1)),\n",
        "            y = fold_scores,\n",
        "            mode = 'markers',\n",
        "            name = 'Fold Scores',\n",
        "            marker = dict(size = 27, color=self._color, symbol='diamond'),\n",
        "            text = [f'{score:.3f}' for score in fold_scores],\n",
        "            hovertemplate = 'Fold %{x}: %{text}<extra></extra>',\n",
        "            hoverlabel = dict(font=dict(size=18))\n",
        "        ))\n",
        "\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x = [1, len(fold_scores)],\n",
        "            y = [mean_score, mean_score],\n",
        "            mode = 'lines',\n",
        "            name = f'Mean: {mean_score:.3f}',\n",
        "            line = dict(dash = 'dash', color = '#B22222'),\n",
        "            hoverinfo = 'none'\n",
        "        ))\n",
        "\n",
        "        fig.update_layout(\n",
        "            title = f'{title} | Cross-validation Mean {metric} Score: {mean_score}',\n",
        "            xaxis_title = 'Fold',\n",
        "            yaxis_title = f'{metric} Score',\n",
        "            plot_bgcolor = 'rgba(247, 230, 202, 1)',\n",
        "            paper_bgcolor = 'rgba(247, 230, 202, 1)',\n",
        "            font = dict(color=self._color),\n",
        "            xaxis = dict(\n",
        "                gridcolor = 'grey',\n",
        "                tickmode = 'linear',\n",
        "                tick0 = 1,\n",
        "                dtick = 1,\n",
        "                range = [0.5, len(fold_scores) + 0.5],\n",
        "                zerolinecolor = 'grey'\n",
        "            ),\n",
        "            yaxis = dict(\n",
        "                gridcolor = 'grey',\n",
        "                zerolinecolor = 'grey'\n",
        "            )\n",
        "        )\n",
        "\n",
        "        fig.show()\n",
        "\n",
        "class Targets:\n",
        "\n",
        "    def __init__(self, data, cat_cols, penalizer, n_splits):\n",
        "\n",
        "        self.data = data\n",
        "        self.cat_cols = cat_cols\n",
        "\n",
        "        self._length = len(self.data)\n",
        "        self._penalizer = penalizer\n",
        "        self._n_splits = n_splits\n",
        "\n",
        "    def _prepare_cv(self):\n",
        "\n",
        "        oof_preds = np.zeros(self._length)\n",
        "\n",
        "        cv = KFold(n_splits=self._n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "        return cv, oof_preds\n",
        "\n",
        "    def validate_model(self, preds, title):\n",
        "\n",
        "        y_true = self.data[['ID', 'efs', 'efs_time', 'race_group']].copy()\n",
        "        y_pred = self.data[['ID']].copy()\n",
        "\n",
        "        y_pred['prediction'] = preds\n",
        "\n",
        "        c_index_score = score(y_true.copy(), y_pred.copy(), 'ID')\n",
        "        print(f'Overall Stratified C-Index Score for {title}: {c_index_score:.4f}')\n",
        "\n",
        "    def create_target1(self):\n",
        "\n",
        "        '''\n",
        "        Constant columns are dropped if they exist in a fold. Otherwise, the code produces error:\n",
        "\n",
        "        delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation:\n",
        "        https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n",
        "        '''\n",
        "\n",
        "        cv, oof_preds = self._prepare_cv()\n",
        "\n",
        "        # Apply one hot encoding to categorical columns\n",
        "        data = pd.get_dummies(self.data, columns=self.cat_cols, drop_first=True).drop('ID', axis=1)\n",
        "\n",
        "        for train_index, valid_index in cv.split(data):\n",
        "\n",
        "            train_data = data.iloc[train_index]\n",
        "            valid_data = data.iloc[valid_index]\n",
        "\n",
        "            # Drop constant columns if they exist\n",
        "            train_data = train_data.loc[:, train_data.nunique() > 1]\n",
        "            valid_data = valid_data[train_data.columns]\n",
        "\n",
        "            cph = CoxPHFitter(penalizer=self._penalizer)\n",
        "            cph.fit(train_data, duration_col='efs_time', event_col='efs')\n",
        "\n",
        "            oof_preds[valid_index] = cph.predict_partial_hazard(valid_data)\n",
        "\n",
        "        self.data['target1'] = oof_preds\n",
        "        self.validate_model(oof_preds, 'Cox')\n",
        "\n",
        "        return self.data\n",
        "\n",
        "    def create_target2(self):\n",
        "\n",
        "        cv, oof_preds = self._prepare_cv()\n",
        "\n",
        "        for train_index, valid_index in cv.split(self.data):\n",
        "\n",
        "            train_data = self.data.iloc[train_index]\n",
        "            valid_data = self.data.iloc[valid_index]\n",
        "\n",
        "            kmf = KaplanMeierFitter()\n",
        "            kmf.fit(durations=train_data['efs_time'], event_observed=train_data['efs'])\n",
        "\n",
        "            oof_preds[valid_index] = kmf.survival_function_at_times(valid_data['efs_time']).values\n",
        "\n",
        "        self.data['target2'] = oof_preds\n",
        "        self.validate_model(oof_preds, 'Kaplan-Meier')\n",
        "\n",
        "        return self.data\n",
        "\n",
        "    def create_target3(self):\n",
        "\n",
        "        cv, oof_preds = self._prepare_cv()\n",
        "\n",
        "        for train_index, valid_index in cv.split(self.data):\n",
        "\n",
        "            train_data = self.data.iloc[train_index]\n",
        "            valid_data = self.data.iloc[valid_index]\n",
        "\n",
        "            naf = NelsonAalenFitter()\n",
        "            naf.fit(durations=train_data['efs_time'], event_observed=train_data['efs'])\n",
        "\n",
        "            oof_preds[valid_index] = -naf.cumulative_hazard_at_times(valid_data['efs_time']).values\n",
        "\n",
        "        self.data['target3'] = oof_preds\n",
        "        self.validate_model(oof_preds, 'Nelson-Aalen')\n",
        "\n",
        "        return self.data\n",
        "\n",
        "    def create_target4(self):\n",
        "\n",
        "        self.data['target4'] = self.data.efs_time.copy()\n",
        "        self.data.loc[self.data.efs == 0, 'target4'] *= -1\n",
        "\n",
        "        return self.data\n",
        "\n",
        "class MD:\n",
        "\n",
        "    def __init__(self, colorscale, color, data, cat_cols, early_stop, penalizer, n_splits):\n",
        "\n",
        "        self.eda = EDA(colorscale, color, data)\n",
        "        self.targets = Targets(data, cat_cols, penalizer, n_splits)\n",
        "\n",
        "        self.data = data\n",
        "        self.cat_cols = cat_cols\n",
        "        self._early_stop = early_stop\n",
        "\n",
        "    def create_targets(self):\n",
        "\n",
        "        self.data = self.targets.create_target1()\n",
        "        self.data = self.targets.create_target2()\n",
        "        self.data = self.targets.create_target3()\n",
        "        self.data = self.targets.create_target4()\n",
        "\n",
        "        return self.data\n",
        "\n",
        "    def train_model(self, params, target, title):\n",
        "\n",
        "        for col in self.cat_cols:\n",
        "            self.data[col] = self.data[col].astype('category')\n",
        "\n",
        "        X = self.data.drop(['ID', 'efs', 'efs_time', 'target1', 'target2', 'target3', 'target4'], axis=1)\n",
        "        y = self.data[target]\n",
        "\n",
        "        models, fold_scores = [], []\n",
        "\n",
        "        cv, oof_preds = self.targets._prepare_cv()\n",
        "\n",
        "        for fold, (train_index, valid_index) in enumerate(cv.split(X, y)):\n",
        "\n",
        "            X_train = X.iloc[train_index]\n",
        "            X_valid = X.iloc[valid_index]\n",
        "\n",
        "            y_train = y.iloc[train_index]\n",
        "            y_valid = y.iloc[valid_index]\n",
        "\n",
        "            if title.startswith('LightGBM'):\n",
        "\n",
        "                model = lgb.LGBMRegressor(**params)\n",
        "\n",
        "                model.fit(\n",
        "                    X_train,\n",
        "                    y_train,\n",
        "                    eval_set=[(X_valid, y_valid)],\n",
        "                    eval_metric='rmse',\n",
        "                    callbacks=[lgb.early_stopping(self._early_stop, verbose=0), lgb.log_evaluation(0)]\n",
        "                )\n",
        "\n",
        "            elif title.startswith('CatBoost'):\n",
        "\n",
        "                model = CatBoostRegressor(**params, verbose=0, cat_features=self.cat_cols)\n",
        "\n",
        "                model.fit(\n",
        "                    X_train,\n",
        "                    y_train,\n",
        "                    eval_set=(X_valid, y_valid),\n",
        "                    early_stopping_rounds=self._early_stop,\n",
        "                    verbose=0\n",
        "                )\n",
        "\n",
        "            models.append(model)\n",
        "\n",
        "            oof_preds[valid_index] = model.predict(X_valid)\n",
        "\n",
        "            y_true_fold = self.data.iloc[valid_index][['ID', 'efs', 'efs_time', 'race_group']].copy()\n",
        "            y_pred_fold = self.data.iloc[valid_index][['ID']].copy()\n",
        "\n",
        "            y_pred_fold['prediction'] = oof_preds[valid_index]\n",
        "\n",
        "            fold_score = score(y_true_fold, y_pred_fold, 'ID')\n",
        "            fold_scores.append(fold_score)\n",
        "\n",
        "        self.eda._plot_cv(fold_scores, title)\n",
        "        self.targets.validate_model(oof_preds, title)\n",
        "\n",
        "        return models, oof_preds\n",
        "\n",
        "    def infer_model(self, data, models):\n",
        "\n",
        "        data = data.drop(['ID'], axis=1)\n",
        "\n",
        "        for col in self.cat_cols:\n",
        "            data[col] = data[col].astype('category')\n",
        "\n",
        "        return np.mean([model.predict(data) for model in models], axis=0)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T16:59:01.162648Z",
          "iopub.execute_input": "2025-02-18T16:59:01.162944Z",
          "iopub.status.idle": "2025-02-18T16:59:01.188367Z",
          "shell.execute_reply.started": "2025-02-18T16:59:01.16292Z",
          "shell.execute_reply": "2025-02-18T16:59:01.187467Z"
        },
        "id": "wAUObv6r8Wcn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "import pytorch_lightning as pl\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, TQDMProgressBar, ModelCheckpoint, StochasticWeightAveraging\n",
        "\n",
        "# ✅ Disable CUDA and enable MPS (Mac Compatibility)\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Disable NVIDIA CUDA\n",
        "os.environ[\"MPS_VISIBLE_DEVICES\"] = \"1\"  # Enable Apple MPS\n",
        "torch.mps.is_available = lambda: True\n",
        "torch.mps.is_built = lambda: True\n",
        "\n",
        "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "\n",
        "pl.seed_everything(50)\n",
        "\n",
        "\n",
        "# ======= Load Pretrained LSTM Model =======\n",
        "class PretrainedLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
        "        super(PretrainedLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])  # Take last hidden state\n",
        "        return out\n",
        "\n",
        "\n",
        "# Load the pre-trained LSTM model\n",
        "pretrained_lstm = PretrainedLSTM(input_dim=50, hidden_dim=128, num_layers=2, output_dim=1)\n",
        "pretrained_lstm.load_state_dict(torch.load(\"lstm_model.pth\", map_location=device))\n",
        "pretrained_lstm.to(device)\n",
        "pretrained_lstm.eval()\n",
        "\n",
        "\n",
        "# ======= Main Model with LSTM Ensemble =======\n",
        "class NN(nn.Module):\n",
        "    def __init__(self, continuous_dim, categorical_cardinality, embedding_dim, projection_dim, hidden_dim, dropout=0):\n",
        "        super(NN, self).__init__()\n",
        "        self.embeddings = nn.ModuleList([\n",
        "            nn.Embedding(cardinality, embedding_dim) for cardinality in categorical_cardinality\n",
        "        ])\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(embedding_dim * len(categorical_cardinality), projection_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(projection_dim, projection_dim)\n",
        "        )\n",
        "        self.lstm = nn.LSTM(projection_dim + continuous_dim, hidden_dim, batch_first=True)\n",
        "        self.batch_norm = nn.BatchNorm1d(hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.out = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x_cat, x_cont):\n",
        "        x_cat = [embedding(x_cat[:, i]) for i, embedding in enumerate(self.embeddings)]\n",
        "        x_cat = torch.cat(x_cat, dim=1)\n",
        "        x_cat = self.projection(x_cat)\n",
        "\n",
        "        x = torch.cat([x_cat, x_cont], dim=1)\n",
        "        x, _ = self.lstm(x.unsqueeze(1))\n",
        "        x = x.squeeze(1)\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.dropout(x)\n",
        "        out_main = self.out(x)\n",
        "\n",
        "        # === Ensemble with Pretrained LSTM ===\n",
        "        with torch.no_grad():\n",
        "            out_lstm = pretrained_lstm(x.unsqueeze(1))\n",
        "\n",
        "        final_output = 0.5 * out_main + 0.5 * out_lstm  # Averaging both models\n",
        "        return final_output, x\n",
        "\n",
        "\n",
        "# ======= PyTorch Lightning Wrapper =======\n",
        "class LitNN(pl.LightningModule):\n",
        "    def __init__(self, continuous_dim, categorical_cardinality, embedding_dim, projection_dim, hidden_dim,\n",
        "                 lr=1e-3, dropout=0.2, weight_decay=1e-3, aux_weight=0.1, margin=0.5, race_index=0):\n",
        "        super(LitNN, self).__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.model = NN(continuous_dim, categorical_cardinality, embedding_dim, projection_dim, hidden_dim, dropout)\n",
        "\n",
        "    def forward(self, x_cat, x_cont):\n",
        "        return self.model(x_cat, x_cont)[0]  # Only return prediction\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=6e-3)\n",
        "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
        "\n",
        "\n",
        "# ======= Train the Model =======\n",
        "def train_final(X_num_train, dl_train, dl_val, transformers, hparams=None, categorical_cols=None):\n",
        "    if hparams is None:\n",
        "        hparams = {\n",
        "            \"embedding_dim\": 16,\n",
        "            \"projection_dim\": 160,\n",
        "            \"hidden_dim\": 80,\n",
        "            \"lr\": 0.03,\n",
        "            \"dropout\": 0.05,\n",
        "            \"aux_weight\": 0.26,\n",
        "            \"margin\": 0.25,\n",
        "            \"weight_decay\": 0.00027\n",
        "        }\n",
        "\n",
        "    model = LitNN(\n",
        "        continuous_dim=X_num_train.shape[1],\n",
        "        categorical_cardinality=[len(t.classes_) for t in transformers],\n",
        "        race_index=categorical_cols.index(\"race_group\"),\n",
        "        **hparams\n",
        "    )\n",
        "\n",
        "    checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\", save_top_k=1)\n",
        "\n",
        "    trainer = pl.Trainer(\n",
        "        accelerator=\"mps\" if torch.backends.mps.is_available() else \"cpu\",\n",
        "        devices=1,\n",
        "        max_epochs=60,\n",
        "        callbacks=[\n",
        "            checkpoint_callback,\n",
        "            LearningRateMonitor(logging_interval='epoch'),\n",
        "            TQDMProgressBar(),\n",
        "            StochasticWeightAveraging(swa_lrs=1e-5, swa_epoch_start=45, annealing_epochs=15)\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    trainer.fit(model, dl_train)\n",
        "    trainer.test(model, dl_val)\n",
        "    return model.eval()\n",
        "\n",
        "\n",
        "# ======= Main Function =======\n",
        "def main(hparams):\n",
        "    test, train_original = load_data()\n",
        "    test['efs_time'] = 1\n",
        "    test['efs'] = 1\n",
        "    test_pred = np.zeros(test.shape[0])\n",
        "\n",
        "    categorical_cols, numerical = [], []  # Replace with actual feature columns\n",
        "    kf = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(train_original, train_original)):\n",
        "        train = train_original.iloc[train_index]\n",
        "        val = train_original.iloc[test_index]\n",
        "        X_cat_val, X_num_train, X_num_val, dl_train, dl_val, transformers = preprocess_data(train, val)\n",
        "        model = train_final(X_num_train, dl_train, dl_val, transformers, categorical_cols=categorical_cols)\n",
        "\n",
        "        X_cat_val, X_num_train, X_num_val, dl_train, dl_val, transformers = preprocess_data(train, test)\n",
        "        pred, _ = model(torch.tensor(X_cat_val, dtype=torch.long), torch.tensor(X_num_val, dtype=torch.float32))\n",
        "        test_pred += pred.detach().cpu().numpy()\n",
        "\n",
        "    subm_data = pd.DataFrame({\"prediction\": -test_pred})\n",
        "    subm_data.to_csv('submission4.csv', index=False)\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "# Run main\n",
        "hparams = None\n",
        "res = main(hparams=None)\n",
        "print(\"Done\")\n"
      ],
      "metadata": {
        "id": "072QspFV-08y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md = MD(CFG.colorscale, CFG.color, train_data, cat_cols, CFG.early_stop, CFG.penalizer, CFG.n_splits)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T16:59:01.189112Z",
          "iopub.execute_input": "2025-02-18T16:59:01.189372Z",
          "iopub.status.idle": "2025-02-18T16:59:01.205545Z",
          "shell.execute_reply.started": "2025-02-18T16:59:01.189351Z",
          "shell.execute_reply": "2025-02-18T16:59:01.204826Z"
        },
        "id": "07YIPSRV8Wcn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = md.create_targets()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T16:59:01.209634Z",
          "iopub.execute_input": "2025-02-18T16:59:01.209896Z",
          "iopub.status.idle": "2025-02-18T17:01:22.345976Z",
          "shell.execute_reply.started": "2025-02-18T16:59:01.209874Z",
          "shell.execute_reply": "2025-02-18T17:01:22.345155Z"
        },
        "id": "GoORWQVW8Wcn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "fe.info(train_data)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:01:22.347468Z",
          "iopub.execute_input": "2025-02-18T17:01:22.347709Z",
          "iopub.status.idle": "2025-02-18T17:01:22.390986Z",
          "shell.execute_reply.started": "2025-02-18T17:01:22.347689Z",
          "shell.execute_reply": "2025-02-18T17:01:22.390256Z"
        },
        "id": "Uhje_30x8Wcn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ctb1_models, ctb1_oof_preds = md.train_model(CFG.ctb_params, target='target1', title='CatBoost')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:01:22.39191Z",
          "iopub.execute_input": "2025-02-18T17:01:22.392219Z",
          "iopub.status.idle": "2025-02-18T17:41:23.37114Z",
          "shell.execute_reply.started": "2025-02-18T17:01:22.392187Z",
          "shell.execute_reply": "2025-02-18T17:41:23.36964Z"
        },
        "id": "ya5CEHly8Wcn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lgb1_models, lgb1_oof_preds = md.train_model(CFG.lgb_params, target='target1', title='LightGBM')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:41:23.373776Z",
          "iopub.status.idle": "2025-02-18T17:41:23.374029Z",
          "shell.execute_reply": "2025-02-18T17:41:23.373925Z"
        },
        "id": "PVWdsEjS8Wcn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ctb1_preds = md.infer_model(test_data, ctb1_models)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:41:23.37476Z",
          "iopub.status.idle": "2025-02-18T17:41:23.375045Z",
          "shell.execute_reply": "2025-02-18T17:41:23.374906Z"
        },
        "id": "6y5P2MqG8Wcn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lgb1_preds = md.infer_model(test_data, lgb1_models)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:41:23.376154Z",
          "iopub.status.idle": "2025-02-18T17:41:23.376546Z",
          "shell.execute_reply": "2025-02-18T17:41:23.376385Z"
        },
        "id": "RsAPL1Al8Wcq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ctb2_models, ctb2_oof_preds = md.train_model(CFG.ctb_params, target='target2', title='CatBoost')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:41:23.377502Z",
          "iopub.status.idle": "2025-02-18T17:41:23.377885Z",
          "shell.execute_reply": "2025-02-18T17:41:23.377709Z"
        },
        "id": "NMJgXwWP8Wcq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lgb2_models, lgb2_oof_preds = md.train_model(CFG.lgb_params, target='target2', title='LightGBM')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:41:23.378788Z",
          "iopub.status.idle": "2025-02-18T17:41:23.379181Z",
          "shell.execute_reply": "2025-02-18T17:41:23.379015Z"
        },
        "id": "T13qsppJ8Wcq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ctb2_preds = md.infer_model(test_data, ctb2_models)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:41:23.380008Z",
          "iopub.status.idle": "2025-02-18T17:41:23.38043Z",
          "shell.execute_reply": "2025-02-18T17:41:23.380252Z"
        },
        "id": "RWPpfhtV8Wcq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lgb2_preds = md.infer_model(test_data, lgb2_models)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:41:23.381376Z",
          "iopub.status.idle": "2025-02-18T17:41:23.381749Z",
          "shell.execute_reply": "2025-02-18T17:41:23.381585Z"
        },
        "id": "pBJ05wYJ8Wcq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ctb3_models, ctb3_oof_preds = md.train_model(CFG.ctb_params, target='target3', title='CatBoost')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:41:23.382389Z",
          "iopub.status.idle": "2025-02-18T17:41:23.382662Z",
          "shell.execute_reply": "2025-02-18T17:41:23.382532Z"
        },
        "id": "9p-cUvM48Wcq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lgb3_models, lgb3_oof_preds = md.train_model(CFG.lgb_params, target='target3', title='LightGBM')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:41:23.383282Z",
          "iopub.status.idle": "2025-02-18T17:41:23.383526Z",
          "shell.execute_reply": "2025-02-18T17:41:23.38342Z"
        },
        "id": "KC9LmqJF8Wcq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ctb3_preds = md.infer_model(test_data, ctb3_models)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:41:23.384188Z",
          "iopub.status.idle": "2025-02-18T17:41:23.384494Z",
          "shell.execute_reply": "2025-02-18T17:41:23.384391Z"
        },
        "id": "o4rlS3pW8Wcq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lgb3_preds = md.infer_model(test_data, lgb3_models)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:41:23.385034Z",
          "iopub.status.idle": "2025-02-18T17:41:23.385383Z",
          "shell.execute_reply": "2025-02-18T17:41:23.385256Z"
        },
        "id": "L8KT66qD8Wcq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "cox1_models, cox1_oof_preds = md.train_model(CFG.cox1_params, target='target4', title='CatBoost')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:41:23.386175Z",
          "iopub.status.idle": "2025-02-18T17:41:23.386529Z",
          "shell.execute_reply": "2025-02-18T17:41:23.386378Z"
        },
        "id": "EF4cTxsR8Wcq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "cox2_models, cox2_oof_preds = md.train_model(CFG.cox2_params, target='target4', title='CatBoost')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:41:23.387465Z",
          "iopub.status.idle": "2025-02-18T17:41:23.387776Z",
          "shell.execute_reply": "2025-02-18T17:41:23.387667Z"
        },
        "id": "Ku8XvyjD8Wcr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "cox1_preds = md.infer_model(test_data, cox1_models)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:41:23.390821Z",
          "iopub.status.idle": "2025-02-18T17:41:23.391172Z",
          "shell.execute_reply": "2025-02-18T17:41:23.391056Z"
        },
        "id": "xy6d9moV8Wcr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "cox2_preds = md.infer_model(test_data, cox2_models)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:41:23.392007Z",
          "iopub.status.idle": "2025-02-18T17:41:23.392338Z",
          "shell.execute_reply": "2025-02-18T17:41:23.392187Z"
        },
        "id": "Y33aAmuQ8Wcr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "oof_preds = [\n",
        "    ctb1_oof_preds,\n",
        "    lgb1_oof_preds,\n",
        "    ctb2_oof_preds,\n",
        "    lgb2_oof_preds,\n",
        "    ctb3_oof_preds,\n",
        "    lgb3_oof_preds,\n",
        "    cox1_oof_preds,\n",
        "    cox2_oof_preds\n",
        "]\n",
        "\n",
        "preds = [\n",
        "    ctb1_preds,\n",
        "    lgb1_preds,\n",
        "    ctb2_preds,\n",
        "    lgb2_preds,\n",
        "    ctb3_preds,\n",
        "    lgb3_preds,\n",
        "    cox1_preds,\n",
        "    cox2_preds\n",
        "]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:41:23.393287Z",
          "iopub.status.idle": "2025-02-18T17:41:23.393578Z",
          "shell.execute_reply": "2025-02-18T17:41:23.39347Z"
        },
        "id": "1lmW83LV8Wcr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ranked_oof_preds = np.array([rankdata(p) for p in oof_preds])\n",
        "ensemble_oof_preds = np.dot(CFG.weights, ranked_oof_preds)\n",
        "md.targets.validate_model(ensemble_oof_preds, 'Ensemble Model')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:41:23.394139Z",
          "iopub.status.idle": "2025-02-18T17:41:23.394478Z",
          "shell.execute_reply": "2025-02-18T17:41:23.39434Z"
        },
        "id": "NCZA4Fyk8Wcr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ranked_preds = np.array([rankdata(p) for p in preds])\n",
        "ensemble_preds = np.dot(CFG.weights, ranked_preds)\n",
        "subm_data = pd.read_csv(CFG.subm_path)\n",
        "subm_data['prediction'] = ensemble_preds"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:41:23.395418Z",
          "iopub.status.idle": "2025-02-18T17:41:23.395754Z",
          "shell.execute_reply": "2025-02-18T17:41:23.395586Z"
        },
        "id": "DTe9p9ss8Wcr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "subm_data.to_csv('submission3.csv', index=False)\n",
        "display(subm_data.head())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T17:41:23.396504Z",
          "iopub.status.idle": "2025-02-18T17:41:23.396784Z",
          "shell.execute_reply": "2025-02-18T17:41:23.396681Z"
        },
        "id": "uJC_Yqsq8Wcr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "hVerwJeC8Wcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ensemble Notebook**"
      ],
      "metadata": {
        "id": "hZ5CxtC-8Wcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import rankdata\n",
        "\n",
        "# Load submission files\n",
        "sub1 = pd.read_csv('/kaggle/working/submission1.csv')\n",
        "sub2 = pd.read_csv('/kaggle/working/submission2.csv')\n",
        "sub3 = pd.read_csv('/kaggle/working/submission3.csv')\n",
        "sub4=pd.read_csv(\"/kaggle/working/submission4.csv\")\n",
        "\n",
        "# Calculate ranks for each submission's predictions\n",
        "rank1 = rankdata(sub1['prediction'], method='average')\n",
        "rank2 = rankdata(sub2['prediction'], method='average')\n",
        "rank3 = rankdata(sub3['prediction'], method='average')\n",
        "\n",
        "# Create DataFrame of ranks and average them\n",
        "rank_df = pd.DataFrame({\n",
        "    'rank1': rank1,\n",
        "    'rank2': rank2,\n",
        "    'rank3': rank3\n",
        "})\n",
        "ensemble_rank = rank_df.mean(axis=1)\n",
        "\n",
        "# Create final submission file with averaged ranks\n",
        "final_sub = sub1[['ID']].copy()\n",
        "final_sub['prediction'] = ensemble_rank\n",
        "final_sub.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "vQG-PIDJ8Wcr"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}